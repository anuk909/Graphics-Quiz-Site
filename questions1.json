[
  {
    "type": "mc",
    "question": "מהו הרעיון המרכזי של Single-Image Learning שהודגש בהרצאה?",
    "options": [
      "שימוש במיליוני תמונות כדי ללמוד סגנון אחיד",
      "ניצול חזרתיות פנימית בטלאים של תמונה בודדת כדי ללמוד ממנה לבדה",
      "החלפת כל שכבות הקונבולוציה בשכבות Fully Connected",
      "חיבור בין שתי תמונות שונות ליצירת תבנית ביניים"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ב־Single-Image Learning מנצלים את העובדה שה-patchים בתמונה מופיעים שוב ושוב ברמות קנה-מידה שונות, ולכן ניתן ללמוד מבנה ומרקם גם ללא דאטה חיצוני."
  },
  {
    "type": "mc",
    "question": "מהו ה-prior שעליו מסתמכת שיטת Deep Image Prior (DIP)?",
    "options": [
      "Regularization חיצוני המבוסס על Gram Matrix",
      "מבנה הרשת הקונבולוציונית עצמו שמעדיף תבניות טבעיות על רעש",
      "מאגר גדול של תמונות מאומנות מראש",
      "טכניקת Data Augmentation אינטנסיבית בחלון 70×70"
    ],
    "correctAnswerIndex": 1,
    "explanation": "גם עם משקולות אקראיים, ארכיטקטורת CNN נוטה לשחזר מבנים מסודרים יותר מרעש ולכן פועלת כ-prior פנימי."
  },
  {
    "type": "mc",
    "question": "באימון DIP מבוצעת האופטימיזציה על…",
    "options": [
      "פיקסלי התמונה עצמה בכל איטרציה",
      "משקולות הרשת בלבד בעוד קלט הרעש נשאר קבוע",
      "וקטור הלטנט Z שמשתנה כל צעד",
      "ה-Discriminator של GAN חיצוני"
    ],
    "correctAnswerIndex": 1,
    "explanation": "בדיפ האופטימיזציה מעדכנת את θ — פרמטרי הרשת — בעוד שהקלט z הוא וקטור רעש קבוע."
  },
  {
    "type": "mc",
    "question": "למה נדרש Early Stopping ב-DIP לפי ההרצאה?",
    "options": [
      "כדי למנוע מאפס-גרדיאנט בשכבות עמוקות",
      "כדי לעצור לפני שהרשת תלמד גם את הרעש והפגמים",
      "כדי לחסוך זמן ולאמן פחות משכבות",
      "כדי להקטין את זיכרון ה-GPU הדרוש לתמונה"
    ],
    "correctAnswerIndex": 1,
    "explanation": "אם ממשיכים יותר מדי איטרציות, הרשת תתאים את עצמה גם לרעש שבקלט ותאבד את אפקט הסינון."
  },
  {
    "type": "mc",
    "question": "Inpainting ב-DIP מבוצע על-ידי…",
    "options": [
      "חישוב הפסד על כל הפיקסלים כולל האזורים החסרים",
      "התעלמות מהאזורים החסרים בעזרת מסכה בינארית ולמידה רק על הפיקסלים הידועים",
      "הזרקת רעש חדש בכל איטרציה במקום התמונה החסרה",
      "הוספת Discriminator מקומי לאזור המסכה"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ה-loss מחושב רק על הפיקסלים שמחוץ למסכה, והרשת משלימה את החסר בעזרת prior המבנה שלה."
  },
  {
    "type": "mc",
    "question": "איזה קשר קיים בין Patch Entropy להצלחת DIP?",
    "options": [
      "אנטרופיה גבוהה מקלה על הרשת ללמוד מהר",
      "אנטרופיה נמוכה מסייעת לרשת לשחזר מבנים חזרתיים בדיוק גבוה",
      "אנטרופיה אינה משפיעה על תהליך השחזור",
      "רק אנטרופיה שלילית מאפשרת Early Stopping"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ככל שה-patchים דומים זה לזה (אנטרופיה נמוכה) קל יותר לרשת לשחזר את התמונה ולסנן רעש."
  },
  {
    "type": "mc",
    "question": "Double-DIP מפרק תמונה לשכבות שונות באמצעות…",
    "options": [
      "GAN יחיד עם Discriminator גלובלי",
      "מספר רשתות DIP נפרדות בתוספת Exclusion Loss בין הרכיבים",
      "רשת יחידה עם Dropout גבוה במיוחד",
      "חישוב PCA ישיר על פיקסלי התמונה"
    ],
    "correctAnswerIndex": 1,
    "explanation": "כל רכיב משוחזר ע\"י DIP ייעודי, ו-Exclusion Loss מבטיח שהרכיבים לא יחפפו סטטיסטית."
  },
  {
    "type": "mc",
    "question": "מה תפקיד Entropy Loss במסכה ב-Double-DIP?",
    "options": [
      "לכפות על המסכה להיות חלקה (Smooth)",
      "לעודד את המסכה להיות בינארית וברורה",
      "להוסיף רעש אקראי למסכה לחיזוק ההפרדה",
      "להחליף את הצורך ב-Exclusion Loss"
    ],
    "correctAnswerIndex": 1,
    "explanation": "מסכה בינארית בעלת אנטרופיה נמוכה מבהירה אילו פיקסלים שייכים לכל רכיב וכך משפרת את הפירוק."
  },
  {
    "type": "mc",
    "question": "ב-SinGAN מאמנים…",
    "options": [
      "רשת אחת ברזולוציה המקורית בלבד",
      "פירמידה של זוגות Generator-Discriminator, אחד לכל רזולוציה",
      "שלושה Generators בשכבות Style שונות",
      "Encoder יחיד עם Loss פיקסלי בלבד"
    ],
    "correctAnswerIndex": 1,
    "explanation": "לכל סקאלה יש גנרטור ומפלה הלומדים מאותה תמונה מוקטנת, והאימון פרוגרסיבי כלפי מעלה."
  },
  {
    "type": "mc",
    "question": "היתרון הבולט של SinGAN הוא…",
    "options": [
      "דרישה למאגר תמונות ענק לאימון",
      "יכולת ללמוד סגנון ומבנה מתמונה בודדת וליצור וריאציות חדשות",
      "תהליך אימון מהיר על כל תמונה",
      "ביטול מוחלט של ארטיפקטים בכל מצב"
    ],
    "correctAnswerIndex": 1,
    "explanation": "SinGAN לומד מהחזרתיות הפנימית של תמונה אחת בלבד ומסוגל להפיק דוגמאות חדשות בסגנון זה."
  },
  {
    "type": "mc",
    "question": "באיזו נקודה מוסיף StyleGAN את הווקטור w לשכבות הגנרטור?",
    "options": [
      "רק בשכבה הראשונה של Upsampling",
      "בכל שכבה דרך מנגנון AdaIN המווסת ערוצי-תכונה",
      "רק בשכבה הסופית לפני Tanh",
      "ב־Discriminator במקום ב-Generator"
    ],
    "correctAnswerIndex": 1,
    "explanation": "AdaIN מזריק את וקטור הסגנון לכל שכבה וכך שולט בהיבטים שונים של התמונה במדרג."
  },
  {
    "type": "mc",
    "question": "StyleGAN2 החליף את AdaIN במנגנון…",
    "options": [
      "Batch Normalization גלובלי",
      "Modulation + Demodulation להפחתת ארטיפקטים",
      "Dropout מבוקר",
      "Spatial Transformer בפלט"
    ],
    "correctAnswerIndex": 1,
    "explanation": "Mod/Demod מרכך סטטיסטיקות ערוצים ומקטין קווים לא רצויים שהתגלו ב-StyleGAN1."
  },
  {
    "type": "mc",
    "question": "GANSpace מגלה כיווני עריכה סמנטיים על-ידי…",
    "options": [
      "חיפוש גרדיאנט טקסטואלי דרך CLIP",
      "PCA על האקטיבציות הפנימיות של StyleGAN ללא תוויות",
      "אימון Mapper מפוקח עם סט תוויות גיל ומגדר",
      "שילוב Exclusion Loss בין שכבות"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ניתוח השונות הגבוהה במרחב הפנימי מגלה צירים המשנים מאפיינים כמו תנוחת ראש או תאורה."
  },
  {
    "type": "mc",
    "question": "בשיטת StyleCLIP – Latent Optimization, מאופטם…",
    "options": [
      "משקולות הגנרטור כולו מחדש",
      "הקוד הלטנטי של תמונה נתונה כך שתתקרב לטקסט ב-CLIP Space",
      "רק שכבת ה-Discriminator הסופית",
      "וקטור רעש ב-StyleGAN’s Z בלבד ללא מעבר ב-W"
    ],
    "correctAnswerIndex": 1,
    "explanation": "Gradient Descent על הקוד הלטנטי מזיז את התמונה לכיוון התיאור הטקסטואלי המבוקש."
  },
  {
    "type": "mc",
    "question": "Global Direction ב-StyleCLIP מגדיר כיוון קבוע במרחב…",
    "options": [
      "Z כדי לשנות טקסטורה דקיקה",
      "S (Style) כדי להחיל שינוי סמנטי בצורה ישירה ומהירה",
      "W בלבד תוך שימוש ב-AdaIN",
      "Latent Mapper מאומן בנפרד"
    ],
    "correctAnswerIndex": 1,
    "explanation": "הכיוון מחושב פעם אחת בעזרת CLIP ואז מוחל מידית על כל תמונה דרך הזזת ה-style codes."
  },
  {
    "type": "mc",
    "question": "אחת המגבלות שהוזכרו לעריכת תכונות בקווים לינאריים במרחב הלטנט היא…",
    "options": [
      "דרישת זיכרון חריגה בזמן ריצה",
      "תכונות מסוימות אינן ניתנות לייצוג מדויק באמצעות כיוון לינארי יחיד",
      "אי-יכולת לשלוט על עוצמת העריכה",
      "היעדר תכונות סמנטיות במרחב W"
    ],
    "correctAnswerIndex": 1,
    "explanation": "תכונות מורכבות עלולות להיות לא-לינאריות; תזוזה בקו ישר יכולה לגרור שינויים בלתי-רצויים."
  },
  {
    "type": "mc",
    "question": "Latent Mapper ב-StyleCLIP מאפשר…",
    "options": [
      "עריכה מהירה בזמן אמת לאחר אימון חד-פעמי",
      "דיוק גבוה יותר ממסלול Latent Optimization",
      "ביטול הצורך ב-CLIP בזמן ריצה",
      "יצירת תמונות ללא הגבלת גודל"
    ],
    "correctAnswerIndex": 0,
    "explanation": "לאחר שה-Mapper מאומן, כל עריכה היא pass יחיד ולכן מהירה, אך פחות מותאמת אישית."
  },
  {
    "type": "open",
    "question": "תאר כיצד חזרתיות פנימית של טלאים מסייעת ל-Single-Image Learning.",
    "correctAnswerText": "בתוך כל תמונה מופיעים טלאים דומים שוב ושוב בקני-מידה שונים. מודל הלומד מהתמונה בלבד יכול לאתר את התבניות החוזרות וכך לחזות מידע חסר או לשחזר מרקם, ללא צורך בדוגמאות חיצוניות.",
    "explanation": "הסטטיסטיקה הפנימית מספקת 'דאטה' מספק בתוך התמונה עצמה."
  },
  {
    "type": "open",
    "question": "מדוע Exclusion Loss נדרש ב-Double-DIP?",
    "correctAnswerText": "Exclusion Loss מעניש חפיפה סטטיסטית בין הרכיבים שנותחו על-ידי שתי רשתות DIP, וכך מבטיח שכל רשת תלמד חלק שונה של התמונה (למשל אובייקט מול רקע) במקום ששתיהן ישחזרו אותו אזור.",
    "explanation": "ללא אילוץ, שתי הרשתות עלולות להתמקד באותו רכיב ולא להשיג פירוק אמיתי."
  },
  {
    "type": "open",
    "question": "הסבר בקצרה את תהליך האימון הפרוגרסיבי ב-SinGAN ולמה הוא חשוב.",
    "correctAnswerText": "האימון מתחיל בגרסה קטנה מאוד של התמונה; גנרטור-מפלה לומדים מבנה גלובלי. לאחר התייצבות, עוברים לרזולוציה גבוהה יותר ומוסיפים פרטים על בסיס הפלט מהשלב הקודם. כך המודל לומד בהדרגה הן תכונות גסות והן טקסטורות עדינות.",
    "explanation": "חלוקת המשימה מקלה על ה-GAN ללמוד בלי לקרוס ומאפשרת יציבות וגיוון."
  },
  {
    "type": "open",
    "question": "הבדל בין מרחבי W, W+ ו-S ב-StyleGAN כפי שהוסבר בהרצאה.",
    "correctAnswerText": "W הוא מרחב ביניים גמיש שמתקבל מרשת מיפוי; W+ נותן וקטור נפרד לכל שכבה וכך מאפשר שליטה מדויקת אך פחות מפוצלת; S הוא מרחב לאחר מודולציה, נחשב עוד יותר disentangled ומתאים לעריכות נקיות.",
    "explanation": "הבחירה במרחב משפיעה על רמת השליטה וה-leakage בין תכונות."
  },
  {
    "type": "open",
    "question": "כיצד Modulation + Demodulation ב-StyleGAN2 מפחית ארטיפקטים יחסית ל-AdaIN?",
    "correctAnswerText": "StyleGAN2 משתמש ב־modulation לעיצוב הפילטרים לפי w, ו־demodulation לנרמול הפלט – כך נמנעים ארטיפקטים כמו קווים חוזרים שנראו ב־StyleGAN1.",
    "explanation": "ה־modulation מכניס סגנון באופן מדויק, וה־demodulation שומר על יציבות בין הערוצים – יחד הם מונעים קווים ותבניות מלאכותיות."
  },
  {
    "type": "open",
    "question": "פרט שלושה צעדים עיקריים בגישת Global Direction ב-StyleCLIP.",
    "correctAnswerText": "1. מגדירים כיוון סמנטי ב-CLIP על-ידי הבדל בין שני טקסטים.\n2. מודדים עבור כל ערוץ במרחב S איך שינוי קטן משפיע על הכיוון ב-CLIP.\n3. בוחרים ערוצים מועילים ומרכיבים וקטור כיוון סגנון שמוחל על תמונות חדשות.",
    "explanation": "השיטה מצרפת כוח חישובי חד-פעמי עם יישום מיידי על תמונות רבות."
  },
  {
    "type": "open",
    "question": "מהי המגבלה שההרצאה ציינה לגבי עריכה לינארית במרחב הלטנט של GAN?",
    "correctAnswerText": "הנחה שתכונה מיוצגת בכיוון לינארי יחיד אינה תמיד מדויקת; לעיתים תכונה מורכבת ולכן תזוזה ישרה משפיעה גם על תכונות אחרות ויוצרת תוצאות בלתי-רצויות.",
    "explanation": "תלות הדדית וביאס בדאטה גורמים לערבוב תכונות לאורך קווים 'ישרים'."
  },
  {
    "type": "open",
    "question": "מה היתרון ומה החיסרון של Latent Mapper בהשוואה ל-Latent Optimization ב-StyleCLIP?",
    "correctAnswerText": "יתרון: העריכה מתבצעת במהירות בזמן ריצה הודות ל-forward יחיד; חיסרון: היא פחות מותאמת אישית ועלולה להיות פחות מדויקת כי המיפוי נלמד באופן כללי מראש.",
    "explanation": "Mapper = מהיר אך גנרי; Optimization = איטי אך מותאם לדוגמה הספציפית."
  },
    {
    "type": "mc",
    "question": "מהו הרעיון המרכזי של Single-Image Learning שהודגש בהרצאה?",
    "options": [
      "שימוש במיליוני תמונות כדי ללמוד סגנון אחיד",
      "ניצול חזרתיות פנימית בטלאים של תמונה בודדת כדי ללמוד ממנה לבדה",
      "החלפת כל שכבות הקונבולוציה בשכבות Fully Connected",
      "חיבור בין שתי תמונות שונות ליצירת תבנית ביניים"
    ],
    "correctAnswerIndex": 1,
    "explanation": "טלאים דומים מופיעים שוב ושוב בתמונה, ולכן הרשת יכולה ללמוד מבנה ומרקם גם ללא דאטה חיצוני."
  },
  {
    "type": "mc",
    "question": "מהו הגורם שמונע מ-DIP ללמוד גם את הרעש בתמונה בעת denoising?",
    "options": [
      "שימוש ב-Dropout גבוה",
      "Early Stopping מוקפד במהלך האופטימיזציה",
      "החלפת L2 ב-Perceptual Loss",
      "הזרקת רעש משתנה בכל צעד"
    ],
    "correctAnswerIndex": 1,
    "explanation": "עוצרים את האימון ברגע שהמבנה שוחזר היטב; אם ממשיכים, הרשת תתחיל להתאים את עצמה גם לרעש."
  },
  {
    "type": "mc",
    "question": "Patch Entropy נמוכה בתמונה מצביעה לרוב על כך ש-DIP…",
    "options": [
      "יתקשה לשחזר את המבנה",
      "יצליח לשחזר בקלות בשל דמיון חוזר בין טלאים",
      "ידרוש רשת עמוקה במיוחד",
      "יהיה חסין מפני overfitting גם ללא Early Stopping"
    ],
    "correctAnswerIndex": 1,
    "explanation": "חזרתיות גבוהה (אנטרופיה נמוכה) מקלה על הרשת לשחזר ולסנן רעש."
  },
  {
    "type": "mc",
    "question": "Double-DIP משתמש ב-Exclusion Loss על מנת…",
    "options": [
      "לאלץ את שתי רשתות DIP לשחזר אזורים שונים ללא חפיפה",
      "להגביר חדות גלובלית בעזרת Perceptual Loss",
      "לכייל אוטומטית את ‎learning rate",
      "לבטל את הצורך במסכה בינארית"
    ],
    "correctAnswerIndex": 0,
    "explanation": "ה-Loss בודק שהפלטים הסטטיסטיים של שתי הרשתות אינם דומים, וכך מפריד רכיבים (למשל אובייקט ורקע)."
  },
  {
    "type": "mc",
    "question": "מדוע מוסיפים Entropy Loss למסכה ב-Double-DIP?",
    "options": [
      "כדי לעודד את המסכה להיות ברזולוציה נמוכה",
      "כדי להפוך את המסכה לבינארית וברורה",
      "כדי להפחית את זמן האימון",
      "כדי ליצור וריאציות רנדומליות ברקע"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ענישת ערכי ביניים דוחפת את הפיקסלים לערכים 0 או 1 ומחדדת את ההפרדה בין השכבות."
  },
  {
    "type": "mc",
    "question": "איזה תהליך אימון מאפיין את SinGAN?",
    "options": [
      "GAN יחיד ברזולוציה המקורית בלבד",
      "פירמידת זוגות Generator–Discriminator, אחד לכל רזולוציה, המאומנת פרוגרסיבית",
      "סט תמונות חיצוני עם תוויות סגנון",
      "שימוש ב-StyleGAN כ-backbone"
    ],
    "correctAnswerIndex": 1,
    "explanation": "מאמנים קודם ברזולוציה נמוכה, מוסיפים פרטים ברזולוציות גבוהות יותר, ומונעים קריסה של הגנרטור."
  },
  {
    "type": "mc",
    "question": "מהי מגבלה מעשית של SinGAN כפי שהוזכרה בהרצאה?",
    "options": [
      "תלות בזוגות תמונות מתואמות",
      "אימון ארוך לכל תמונה והגיוון מוגבל לחזרתיות הפנימית",
      "חוסר יכולת לעבוד על תמונות קטנות מ-256×256",
      "רגישות גבוהה לרעש בקלט"
    ],
    "correctAnswerIndex": 1,
    "explanation": "צריך לאמן מודל מחדש לכל תמונה, והווריאציות נובעות רק מתבניות שמצויות בתמונה עצמה."
  },
  {
    "type": "mc",
    "question": "Modulation + Demodulation ב-StyleGAN2 פותר בעיקר…",
    "options": [
      "חוסר שליטה ברזולוציה",
      "ארטיפקטים כמו קווים חוזרים שבלטו ב-StyleGAN1",
      "Mode Collapse מתמשך",
      "צריכת זיכרון גבוהה ב-Discriminator"
    ],
    "correctAnswerIndex": 1,
    "explanation": "נרמול הערוצים לאחר המודולציה מונע קווים ותבניות מלאכותיות."
  },
  {
    "type": "mc",
    "question": "GANSpace מגלה כיווני עריכה במרחב הלטנט באמצעות…",
    "options": [
      "CLIP Loss וטקסט חופשי",
      "PCA על האקטיבציות הפנימיות של StyleGAN",
      "אימון Discriminator נוסף עם תוויות גיל ומגדר",
      "השוואת תמונות אמיתיות לפלטי הגנרטור"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ניתוח PCA חושף צירים סמנטיים עיקריים ללא תוויות."
  },
  {
    "type": "mc",
    "question": "ב-StyleCLIP – Latent Optimization, מה מעודכּן על-ידי ה-Gradient?",
    "options": [
      "משקולות הגנרטור כולו",
      "הקוד הלטנטי של התמונה בלבד",
      "רק וקטור רעש ב-Z-space",
      "שכבת ה-Discriminator הסופית"
    ],
    "correctAnswerIndex": 1,
    "explanation": "מבצעים Descent ישירות על הלטנט כך שהתמונה תתאים לטקסט במרחב CLIP."
  },
  {
    "type": "mc",
    "question": "Latent Mapper ב-StyleCLIP מהיר אך פחות מותאם אישית משום שהוא…",
    "options": [
      "דל בפרמטרים וסובל מ-mode collapse",
      "רשת feed-forward קבועה שאינה מותאמת לתמונה הספציפית",
      "מחליף את CLIP בשכבת Softmax",
      "משתמש רק במרחב Z ולא ב-W"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ה-Mapper לומד כללית מראש; בעת ריצה אינו מבצע אופטימיזציה ספציפית ולכן מהיר אך 'גנרי'."
  },
  {
    "type": "open",
    "question": "כיצד Entropy Loss תורם להפיכת המסכה ב-Double-DIP לבינארית?",
    "correctAnswerText": "ה-Loss מעניש פיקסלים בעלי ערכי ביניים במסכה ומעודד אותם להתכנס ל-0 או 1, כך שהמסכה הופכת חדה וברורה.",
    "explanation": "בינאריות מובהקת מאפשרת לכל רשת DIP ללמוד רכיב ייחודי בלי חפיפה."
  },
  {
    "type": "open",
    "question": "למה Early Stopping חיוני ב-Deep Image Prior בעת סילוק רעש?",
    "correctAnswerText": "בשלב מוקדם הרשת משחזרת את המבנה; אם ממשיכים לאמן היא גם תלמד את הרעש. עצירה בזמן מונעת זאת ומשאירה פלט נקי.",
    "explanation": "הרשת לומדת לפי סדר 'קל-לקשה': מבנה קודם, רעש אחר-כך."
  },
  {
    "type": "open",
    "question": "תאר בקצרה את שלבי האימון הפרוגרסיבי של SinGAN ולמה הם מונעים Mode Collapse.",
    "correctAnswerText": "מאמנים GAN קטן על גרסת התמונה ברזולוציה נמוכה, מוסיפים עוד זוג GAN ברזולוציה גבוהה יותר שממשיך מהפלט הקודם, וכן הלאה. בכל שלב המודל פותר תת-בעיה קלה יותר, ולכן נשמר גיוון ואינו קורס לדוגמה יחידה.",
    "explanation": "חלוקת המשימה לרמות מורידה עומס חיפוש בכל שלב ומשמרת וריאציה."
  },
  {
    "type": "open",
    "question": "כיצד Modulation + Demodulation מאזן ערוצים ב-StyleGAN2?",
    "correctAnswerText": "ה-modulation מכפיל את הפילטרים בסקלת סגנון הנגזרת מ-w; ה-demodulation מנרמל אותם כך שלכל ערוץ תהיה עוצמה דומה, ובכך נמנעים קפיצות ערכים שמייצרות ארטיפקטים.",
    "explanation": "שמירה על ממוצע ואנרגיה יציבים בכל הערוצים מפחיתה קווים ותבניות מלאכותיות."
  },
  {
    "type": "open",
    "question": "מדוע כיווני העריכה שנחשפו ב-GANSpace נחשבים ל-Unsupervised?",
    "correctAnswerText": "הכיוונים מתקבלים על-ידי PCA בלבד, בלי שימוש בתוויות או בטקסט, ולכן מגלים מבני שונות סמנטיים בצורה בלתי-מונחית.",
    "explanation": "השיטה מסתמכת על סטטיסטיקת האקטיבציות של הרשת ולא על מידע חיצוני."
  },
  {
    "type": "mc",
    "question": "איזו טכניקה מזכירה ההרצאה לשימור זהות פנים בעת עריכה ב-StyleGAN?",
    "options": [
      "הוספת Loss של CLIP על הטקסט המקורי",
      "Identity Loss המבוסס על רשת זיהוי פנים (ArcFace) במקביל לעריכת CLIP",
      "שימוש רק במרחב Z ללא רעש סטוכסטי",
      "כפיית ה-Mapper לעבוד ב-Z+"
    ],
    "correctAnswerIndex": 1,
    "explanation": "Identity Loss מודד מרחק תכונות פנים ומוודא שהעריכה לא פוגעת בזיהוי."
  },
  {
    "type": "open",
    "question": "כיצד ניתן להשתמש ב-Deep Image Prior לביצוע Super-Resolution על תמונה בודדת בלבד?",
    "correctAnswerText": "מגדילים את התמונה הנמוכה לרזולוציית היעד, מזינים אותה כטארגט, ומאכילים את הרשת רעש קבוע. בזמן האופטימיזציה הרשת לומדת מפני החזרתיות של הטלאים להפיץ פרטים עדינים ולהשלים תדרים גבוהים, כל עוד עוצרים לפני שהיא מתחילה לשחזר את הרעש המקורי של הקלט.",
    "explanation": "DIP פועל כ-prior מבני: הוא משחזר תחילה תבניות טבעיות ולאחר זמן רב מתכנס גם לרעש, לכן Early Stopping קריטי."
  },
  {
    "type": "open",
    "question": "הסבר כיצד Double-DIP מסוגל לבצע הפרדת אובייקט-רקע (segmentation) ללא דאטה מתויג.",
    "correctAnswerText": "מריצים שתי רשתות DIP במקביל, אחת לומדת את הרקע ואחת את האובייקט. מסכה לומדת ייעודית קובעת תרומה של כל רשת לכל פיקסל. Exclusion Loss מבטיח שהשחזורים סטטיסטית בלתי-חופפים ו-Entropy Loss דוחף את המסכה להיות בינארית, כך שהאובייקט נבדל מהרקע בלי תוויות חיצוניות.",
    "explanation": "ה-prior המבני של DIP + אילוצי חפיפה/בינאריות מספקים חלוקה טבעית בין רכיבים שונים בתמונה."
  },
  {
    "type": "open",
    "question": "מהו תהליך StyleGAN Inversion ולמה הוא חיוני לעריכת תמונות אמיתיות?",
    "correctAnswerText": "Inversion היא מציאת קוד לטנט (w או w+) כזה שהגנרטור משחזר את התמונה האמיתית במידת דיוק גבוהה. לאחר שנמצאה התאמה, אפשר להזיז את הקוד בכיוון סמנטי ידוע או עם CLIP ואז לייצר גרסה ערוכה; לבסוף מפיקים את התוצאה ברזולוציית הגנרטור.",
    "explanation": "בלי Inversion אין דרך למפות תמונה קיימת למרחב העריכה של StyleGAN ולכן לא ניתן לבצע שינוי מבוקר."
  },
  {
    "type": "open",
    "question": "ציין שני יתרונות לשימוש במרחב W+ (וקטור שונה לכל שכבה) במקום W יחיד בעת העריכת לטנט.",
    "correctAnswerText": "1. מאפשר שליטה מדויקת ברמות פירוט שונות – שכבות מוקדמות קובעות מבנה, מאוחרות קובעות טקסטורה.\n2. משפר שחזור (inversion) כי כל שכבה יכולה לפצות על שגיאות מקומיות, ולכן התמונה הערוכה שומרת זהות טובה יותר.",
    "explanation": "הגדלת דרגת החופש במרחב W+ מפחיתה דליפת תכונות בין שכבות ומגדילה יכולת התאמה."
  },
  {
    "type": "open",
    "question": "כיצד מפות הרעש (noise maps) ב-StyleGAN2 תורמות למיקרו-וריאציה ולמה הן אינן מתאימות לעריכה סמנטית?",
    "correctAnswerText": "Noise maps מוזרקות אחרי כל קונבולוציה ומוסיפות תבניות אקראיות עדינות (נקבוביות עור, סיבים בשיער). הן אינן מקודדות ב-w ולכן קשה לשלוט בהן סמנטית; שינוי ה-w לא משנה את הרעש, אלא רק את התוכן והסגנון הגלובליים.",
    "explanation": "רעש סטוכסטי מוסיף ריאליזם אבל אינו מייצג משמעות סמנטית, ולכן אינו יעד לעריכת תוכן מכוונת."
  },
  {
    "type": "open",
    "question": "הסבר את ההבדל בין Global Direction ל-Local CLIP Editing ב-StyleCLIP.",
    "correctAnswerText": "Global Direction מחושב פעם אחת לכל תכונה ומוחל כשינוי לינארי אחיד על קוד S; Local Editing מבצע אופטימיזציה ייחודית לקוד תמונה-אחת כדי להתאים לטקסט, ולכן מדויק יותר אך איטי. הראשוני מהיר וגנרי, השני מותאם אישית.",
    "explanation": "Global = pass מהיר ללא גרדיאנט; Local = Gradient Descent ספציפי המבטיח תוצאה מותאמת."
  },
  {
    "type": "open",
    "question": "ציין מגבלה אחת של SinGAN כאשר מנסים ליצור וריאציות משמעותית שונות מהתמונה המקורית.",
    "correctAnswerText": "SinGAN מסוגל רק לשנות ולסדר מחדש את התבניות החוזרות שכבר קיימות בתמונה, ולכן אינו יכול להוסיף אובייקטים או טקסטורות חדשות לגמרי שלא נצפו בדגימה היחידה.",
    "explanation": "ה-GAN לומד את חלוקת הטלאים המקורית בלבד; ללא מידע חיצוני לא ידע ליצור תוכן חדש."
  },
  {
    "type": "open",
    "question": "למה StyleGAN2 משתמש ב-Randomized Layer Noise בנוסף ל-modulation/demodulation, ומה עלול לקרות אם נבטל אותו לחלוטין?",
    "correctAnswerText": "רעש אקראי מוסיף פרטים סטוכסטיים (לדוגמה, נקבוביות עור שונות בכל ריצה) ומונע תבניות משעממות זהות. אם מבטלים אותו, התמונה תיראה נקייה מדי, חיה פחות ועלולה לחשוף סימטריות מלאכותיות של הפילטרים.",
    "explanation": "רעש מגדיל מגוון ו-perceptual realism, במיוחד באזורים עתירי-תדר."
  },
  {
    "type": "mc",
    "question": "איזו שיטת Inversion דוגלת בשימוש ברשת encoder ישירה לקבלת w+ תוך הקרבת דיוק מול מהירות?",
    "options": [
      "e4e",
      "Latent Optimization קלאסי",
      "PTI (Pivotal Tuning)",
      "StyleCLIP Global Direction"
    ],
    "correctAnswerIndex": 0,
    "explanation": "e4e (Encoder for Editing) מפיק קוד במהירות אך פחות מדויק מאופטימיזציה מלאה."
  }
]
