[
  {
    "type": "mc",
    "question": "מהו הרעיון המרכזי של Single-Image Learning שהודגש בהרצאה?",
    "options": [
      "שימוש במיליוני תמונות כדי ללמוד סגנון אחיד",
      "ניצול חזרתיות פנימית בטלאים של תמונה בודדת כדי ללמוד ממנה לבדה",
      "החלפת כל שכבות הקונבולוציה בשכבות Fully Connected",
      "חיבור בין שתי תמונות שונות ליצירת תבנית ביניים"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ב־Single-Image Learning מנצלים את העובדה שה-patchים בתמונה מופיעים שוב ושוב ברמות קנה-מידה שונות, ולכן ניתן ללמוד מבנה ומרקם גם ללא דאטה חיצוני."
  },
  {
    "type": "mc",
    "question": "מהו ה-prior שעליו מסתמכת שיטת Deep Image Prior (DIP)?",
    "options": [
      "Regularization חיצוני המבוסס על Gram Matrix",
      "מבנה הרשת הקונבולוציונית עצמו שמעדיף תבניות טבעיות על רעש",
      "מאגר גדול של תמונות מאומנות מראש",
      "טכניקת Data Augmentation אינטנסיבית בחלון 70×70"
    ],
    "correctAnswerIndex": 1,
    "explanation": "גם עם משקולות אקראיים, ארכיטקטורת CNN נוטה לשחזר מבנים מסודרים יותר מרעש ולכן פועלת כ-prior פנימי."
  },
  {
    "type": "mc",
    "question": "באימון DIP מבוצעת האופטימיזציה על…",
    "options": [
      "פיקסלי התמונה עצמה בכל איטרציה",
      "משקולות הרשת בלבד בעוד קלט הרעש נשאר קבוע",
      "וקטור הלטנט Z שמשתנה כל צעד",
      "ה-Discriminator של GAN חיצוני"
    ],
    "correctAnswerIndex": 1,
    "explanation": "בדיפ האופטימיזציה מעדכנת את θ — פרמטרי הרשת — בעוד שהקלט z הוא וקטור רעש קבוע."
  },
  {
    "type": "mc",
    "question": "למה נדרש Early Stopping ב-DIP לפי ההרצאה?",
    "options": [
      "כדי למנוע מאפס-גרדיאנט בשכבות עמוקות",
      "כדי לעצור לפני שהרשת תלמד גם את הרעש והפגמים",
      "כדי לחסוך זמן ולאמן פחות משכבות",
      "כדי להקטין את זיכרון ה-GPU הדרוש לתמונה"
    ],
    "correctAnswerIndex": 1,
    "explanation": "אם ממשיכים יותר מדי איטרציות, הרשת תתאים את עצמה גם לרעש שבקלט ותאבד את אפקט הסינון."
  },
  {
    "type": "mc",
    "question": "Inpainting ב-DIP מבוצע על-ידי…",
    "options": [
      "חישוב הפסד על כל הפיקסלים כולל האזורים החסרים",
      "התעלמות מהאזורים החסרים בעזרת מסכה בינארית ולמידה רק על הפיקסלים הידועים",
      "הזרקת רעש חדש בכל איטרציה במקום התמונה החסרה",
      "הוספת Discriminator מקומי לאזור המסכה"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ה-loss מחושב רק על הפיקסלים שמחוץ למסכה, והרשת משלימה את החסר בעזרת prior המבנה שלה."
  },
  {
    "type": "mc",
    "question": "איזה קשר קיים בין Patch Entropy להצלחת DIP?",
    "options": [
      "אנטרופיה גבוהה מקלה על הרשת ללמוד מהר",
      "אנטרופיה נמוכה מסייעת לרשת לשחזר מבנים חזרתיים בדיוק גבוה",
      "אנטרופיה אינה משפיעה על תהליך השחזור",
      "רק אנטרופיה שלילית מאפשרת Early Stopping"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ככל שה-patchים דומים זה לזה (אנטרופיה נמוכה) קל יותר לרשת לשחזר את התמונה ולסנן רעש."
  },
  {
    "type": "mc",
    "question": "Double-DIP מפרק תמונה לשכבות שונות באמצעות…",
    "options": [
      "GAN יחיד עם Discriminator גלובלי",
      "מספר רשתות DIP נפרדות בתוספת Exclusion Loss בין הרכיבים",
      "רשת יחידה עם Dropout גבוה במיוחד",
      "חישוב PCA ישיר על פיקסלי התמונה"
    ],
    "correctAnswerIndex": 1,
    "explanation": "כל רכיב משוחזר ע\"י DIP ייעודי, ו-Exclusion Loss מבטיח שהרכיבים לא יחפפו סטטיסטית."
  },
  {
    "type": "mc",
    "question": "מה תפקיד Entropy Loss במסכה ב-Double-DIP?",
    "options": [
      "לכפות על המסכה להיות חלקה (Smooth)",
      "לעודד את המסכה להיות בינארית וברורה",
      "להוסיף רעש אקראי למסכה לחיזוק ההפרדה",
      "להחליף את הצורך ב-Exclusion Loss"
    ],
    "correctAnswerIndex": 1,
    "explanation": "מסכה בינארית בעלת אנטרופיה נמוכה מבהירה אילו פיקסלים שייכים לכל רכיב וכך משפרת את הפירוק."
  },
  {
    "type": "mc",
    "question": "ב-SinGAN מאמנים…",
    "options": [
      "רשת אחת ברזולוציה המקורית בלבד",
      "פירמידה של זוגות Generator-Discriminator, אחד לכל רזולוציה",
      "שלושה Generators בשכבות Style שונות",
      "Encoder יחיד עם Loss פיקסלי בלבד"
    ],
    "correctAnswerIndex": 1,
    "explanation": "לכל סקאלה יש גנרטור ומפלה הלומדים מאותה תמונה מוקטנת, והאימון פרוגרסיבי כלפי מעלה."
  },
  {
    "type": "mc",
    "question": "היתרון הבולט של SinGAN הוא…",
    "options": [
      "דרישה למאגר תמונות ענק לאימון",
      "יכולת ללמוד סגנון ומבנה מתמונה בודדת וליצור וריאציות חדשות",
      "תהליך אימון מהיר על כל תמונה",
      "ביטול מוחלט של ארטיפקטים בכל מצב"
    ],
    "correctAnswerIndex": 1,
    "explanation": "SinGAN לומד מהחזרתיות הפנימית של תמונה אחת בלבד ומסוגל להפיק דוגמאות חדשות בסגנון זה."
  },
  {
    "type": "mc",
    "question": "באיזו נקודה מוסיף StyleGAN את הווקטור w לשכבות הגנרטור?",
    "options": [
      "רק בשכבה הראשונה של Upsampling",
      "בכל שכבה דרך מנגנון AdaIN המווסת ערוצי-תכונה",
      "רק בשכבה הסופית לפני Tanh",
      "ב־Discriminator במקום ב-Generator"
    ],
    "correctAnswerIndex": 1,
    "explanation": "AdaIN מזריק את וקטור הסגנון לכל שכבה וכך שולט בהיבטים שונים של התמונה במדרג."
  },
  {
    "type": "mc",
    "question": "StyleGAN2 החליף את AdaIN במנגנון…",
    "options": [
      "Batch Normalization גלובלי",
      "Modulation + Demodulation להפחתת ארטיפקטים",
      "Dropout מבוקר",
      "Spatial Transformer בפלט"
    ],
    "correctAnswerIndex": 1,
    "explanation": "Mod/Demod מרכך סטטיסטיקות ערוצים ומקטין קווים לא רצויים שהתגלו ב-StyleGAN1."
  },
  {
    "type": "mc",
    "question": "GANSpace מגלה כיווני עריכה סמנטיים על-ידי…",
    "options": [
      "חיפוש גרדיאנט טקסטואלי דרך CLIP",
      "PCA על האקטיבציות הפנימיות של StyleGAN ללא תוויות",
      "אימון Mapper מפוקח עם סט תוויות גיל ומגדר",
      "שילוב Exclusion Loss בין שכבות"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ניתוח השונות הגבוהה במרחב הפנימי מגלה צירים המשנים מאפיינים כמו תנוחת ראש או תאורה."
  },
  {
    "type": "mc",
    "question": "בשיטת StyleCLIP – Latent Optimization, מאופטם…",
    "options": [
      "משקולות הגנרטור כולו מחדש",
      "הקוד הלטנטי של תמונה נתונה כך שתתקרב לטקסט ב-CLIP Space",
      "רק שכבת ה-Discriminator הסופית",
      "וקטור רעש ב-StyleGAN’s Z בלבד ללא מעבר ב-W"
    ],
    "correctAnswerIndex": 1,
    "explanation": "Gradient Descent על הקוד הלטנטי מזיז את התמונה לכיוון התיאור הטקסטואלי המבוקש."
  },
  {
    "type": "mc",
    "question": "Global Direction ב-StyleCLIP מגדיר כיוון קבוע במרחב…",
    "options": [
      "Z כדי לשנות טקסטורה דקיקה",
      "S (Style) כדי להחיל שינוי סמנטי בצורה ישירה ומהירה",
      "W בלבד תוך שימוש ב-AdaIN",
      "Latent Mapper מאומן בנפרד"
    ],
    "correctAnswerIndex": 1,
    "explanation": "הכיוון מחושב פעם אחת בעזרת CLIP ואז מוחל מידית על כל תמונה דרך הזזת ה-style codes."
  },
  {
    "type": "mc",
    "question": "אחת המגבלות שהוזכרו לעריכת תכונות בקווים לינאריים במרחב הלטנט היא…",
    "options": [
      "דרישת זיכרון חריגה בזמן ריצה",
      "תכונות מסוימות אינן ניתנות לייצוג מדויק באמצעות כיוון לינארי יחיד",
      "אי-יכולת לשלוט על עוצמת העריכה",
      "היעדר תכונות סמנטיות במרחב W"
    ],
    "correctAnswerIndex": 1,
    "explanation": "תכונות מורכבות עלולות להיות לא-לינאריות; תזוזה בקו ישר יכולה לגרור שינויים בלתי-רצויים."
  },
  {
    "type": "mc",
    "question": "Latent Mapper ב-StyleCLIP מאפשר…",
    "options": [
      "עריכה מהירה בזמן אמת לאחר אימון חד-פעמי",
      "דיוק גבוה יותר ממסלול Latent Optimization",
      "ביטול הצורך ב-CLIP בזמן ריצה",
      "יצירת תמונות ללא הגבלת גודל"
    ],
    "correctAnswerIndex": 0,
    "explanation": "לאחר שה-Mapper מאומן, כל עריכה היא pass יחיד ולכן מהירה, אך פחות מותאמת אישית."
  },
  {
    "type": "open",
    "question": "תאר כיצד חזרתיות פנימית של טלאים מסייעת ל-Single-Image Learning.",
    "correctAnswerText": "בתוך כל תמונה מופיעים טלאים דומים שוב ושוב בקני-מידה שונים. מודל הלומד מהתמונה בלבד יכול לאתר את התבניות החוזרות וכך לחזות מידע חסר או לשחזר מרקם, ללא צורך בדוגמאות חיצוניות.",
    "explanation": "הסטטיסטיקה הפנימית מספקת 'דאטה' מספק בתוך התמונה עצמה."
  },
  {
    "type": "open",
    "question": "מדוע Exclusion Loss נדרש ב-Double-DIP?",
    "correctAnswerText": "Exclusion Loss מעניש חפיפה סטטיסטית בין הרכיבים שנותחו על-ידי שתי רשתות DIP, וכך מבטיח שכל רשת תלמד חלק שונה של התמונה (למשל אובייקט מול רקע) במקום ששתיהן ישחזרו אותו אזור.",
    "explanation": "ללא אילוץ, שתי הרשתות עלולות להתמקד באותו רכיב ולא להשיג פירוק אמיתי."
  },
  {
    "type": "open",
    "question": "הסבר בקצרה את תהליך האימון הפרוגרסיבי ב-SinGAN ולמה הוא חשוב.",
    "correctAnswerText": "האימון מתחיל בגרסה קטנה מאוד של התמונה; גנרטור-מפלה לומדים מבנה גלובלי. לאחר התייצבות, עוברים לרזולוציה גבוהה יותר ומוסיפים פרטים על בסיס הפלט מהשלב הקודם. כך המודל לומד בהדרגה הן תכונות גסות והן טקסטורות עדינות.",
    "explanation": "חלוקת המשימה מקלה על ה-GAN ללמוד בלי לקרוס ומאפשרת יציבות וגיוון."
  },
  {
    "type": "open",
    "question": "הבדל בין מרחבי W, W+ ו-S ב-StyleGAN כפי שהוסבר בהרצאה.",
    "correctAnswerText": "W הוא מרחב ביניים גמיש שמתקבל מרשת מיפוי; W+ נותן וקטור נפרד לכל שכבה וכך מאפשר שליטה מדויקת אך פחות מפוצלת; S הוא מרחב לאחר מודולציה, נחשב עוד יותר disentangled ומתאים לעריכות נקיות.",
    "explanation": "הבחירה במרחב משפיעה על רמת השליטה וה-leakage בין תכונות."
  },
  {
    "type": "open",
    "question": "כיצד Modulation + Demodulation ב-StyleGAN2 מפחית ארטיפקטים יחסית ל-AdaIN?",
    "correctAnswerText": "StyleGAN2 משתמש ב־modulation לעיצוב הפילטרים לפי w, ו־demodulation לנרמול הפלט – כך נמנעים ארטיפקטים כמו קווים חוזרים שנראו ב־StyleGAN1.",
    "explanation": "ה־modulation מכניס סגנון באופן מדויק, וה־demodulation שומר על יציבות בין הערוצים – יחד הם מונעים קווים ותבניות מלאכותיות."
  },
  {
    "type": "open",
    "question": "פרט שלושה צעדים עיקריים בגישת Global Direction ב-StyleCLIP.",
    "correctAnswerText": "1. מגדירים כיוון סמנטי ב-CLIP על-ידי הבדל בין שני טקסטים.\n2. מודדים עבור כל ערוץ במרחב S איך שינוי קטן משפיע על הכיוון ב-CLIP.\n3. בוחרים ערוצים מועילים ומרכיבים וקטור כיוון סגנון שמוחל על תמונות חדשות.",
    "explanation": "השיטה מצרפת כוח חישובי חד-פעמי עם יישום מיידי על תמונות רבות."
  },
  {
    "type": "open",
    "question": "מהי המגבלה שההרצאה ציינה לגבי עריכה לינארית במרחב הלטנט של GAN?",
    "correctAnswerText": "הנחה שתכונה מיוצגת בכיוון לינארי יחיד אינה תמיד מדויקת; לעיתים תכונה מורכבת ולכן תזוזה ישרה משפיעה גם על תכונות אחרות ויוצרת תוצאות בלתי-רצויות.",
    "explanation": "תלות הדדית וביאס בדאטה גורמים לערבוב תכונות לאורך קווים 'ישרים'."
  },
  {
    "type": "open",
    "question": "מה היתרון ומה החיסרון של Latent Mapper בהשוואה ל-Latent Optimization ב-StyleCLIP?",
    "correctAnswerText": "יתרון: העריכה מתבצעת במהירות בזמן ריצה הודות ל-forward יחיד; חיסרון: היא פחות מותאמת אישית ועלולה להיות פחות מדויקת כי המיפוי נלמד באופן כללי מראש.",
    "explanation": "Mapper = מהיר אך גנרי; Optimization = איטי אך מותאם לדוגמה הספציפית."
  },
  {
    "type": "mc",
    "question": "לפי ההרצאה, מה הופך את Single-Image Learning לאפשרי למרות שיש רק תמונה אחת?",
    "options": [
      "שימוש במודל טרנספורמר מאומן מראש",
      "חזרתיות פנימית של טלאים ברמות קנה-מידה שונות באותה תמונה",
      "תוספת רעש משתנה בכל איטרציה שמדמה דאטה חיצוני",
      "התניה על תוויות סמנטיות שמופקות מאלגוריתם חיצוני"
    ],
    "correctAnswerIndex": 1,
    "explanation": "טלאים דומים חוזרים שוב ושוב בתמונה, ולכן הרשת יכולה ללמוד מהם ללא צורך במאגר חיצוני. :contentReference[oaicite:0]{index=0}:contentReference[oaicite:1]{index=1}"
  },
  {
    "type": "mc",
    "question": "מהו גורם המפתח שמונע מ-DIP ללמוד גם את הרעש הלא רצוי בתמונה?",
    "options": [
      "שימוש ב-Dropout גבוה",
      "Early Stopping מוקפד במהלך האופטימיזציה",
      "החלפת L2 ב-Perceptual Loss",
      "הזרקה של רעש משתנה בכל צעד"
    ],
    "correctAnswerIndex": 1,
    "explanation": "אם עוצרים מוקדם, הרשת משחזרת את המבנה אך לא מספיקה להתאים את עצמה לרעש. :contentReference[oaicite:2]{index=2}:contentReference[oaicite:3]{index=3}"
  },
  {
    "type": "mc",
    "question": "Patch Entropy נמוכה בתמונה מצביעה על כך ש-DIP…",
    "options": [
      "יתקשה לשחזר את המבנה",
      "יצליח לשחזר בקלות בשל דמיון חוזר בין טלאים",
      "ידרוש יותר שכבות ב-U-Net",
      "יהיה חסין מפני Overfitting ללא Early Stopping"
    ],
    "correctAnswerIndex": 1,
    "explanation": "תמונות עם חזרתיות מסודרת (אנטרופיה נמוכה) ניתנות לשחזור מדויק יותר. :contentReference[oaicite:4]{index=4}:contentReference[oaicite:5]{index=5}"
  },
  {
    "type": "mc",
    "question": "Double-DIP משתמש ב-Exclusion Loss כדי…",
    "options": [
      "לאלץ את שתי רשתות ה-DIP לשחזר אזורים לא חופפים",
      "להגביר חדות גלובלית בעזרת Perceptual Loss",
      "לכייל אוטומטית את ה-learning rate",
      "לבטל את הצורך במסכה בינארית"
    ],
    "correctAnswerIndex": 0,
    "explanation": "ה-Exclusion Loss בודק שהרכיבים הנפרדים אינם משתפים תבניות סטטיסטיות. :contentReference[oaicite:6]{index=6}:contentReference[oaicite:7]{index=7}"
  },
  {
    "type": "mc",
    "question": "מדוע מוסיפים Entropy Loss למסכה ב-Double-DIP?",
    "options": [
      "כדי לעודד את המסכה להיות ברזולוציה נמוכה",
      "כדי להפוך את המסכה לבינארית וברורה",
      "כדי להפחית את זמן האימון",
      "כדי לייצר וריאציות רנדומליות ברקע"
    ],
    "correctAnswerIndex": 1,
    "explanation": "Entropy Loss נמוך דוחף את המסכה לערכים 0/1 ומפריד היטב בין השכבות. :contentReference[oaicite:8]{index=8}:contentReference[oaicite:9]{index=9}"
  },
  {
    "type": "mc",
    "question": "איזה היגד מתאר נכונה את אימון SinGAN?",
    "options": [
      "מאמנים Generator יחיד על התמונה ברזולוציה המקורית בלבד",
      "מאמנים זוג Generator–Discriminator לכל רמת רזולוציה בפירמידה באופן פרוגרסיבי",
      "דורשים סט תמונות דומות בגודל משתנה",
      "משתמשים ב-StyleGAN כ-backbone"
    ],
    "correctAnswerIndex": 1,
    "explanation": "SinGAN בונה פירמידה; בכל רמה מאמנים GAN קטן ואז עוברים לרמה הבאה. :contentReference[oaicite:10]{index=10}:contentReference[oaicite:11]{index=11}"
  },
  {
    "type": "mc",
    "question": "חיסרון מעשי של SinGAN לפי ההרצאה הוא…",
    "options": [
      "תלות ב-paired data",
      "אימון ארוך לכל תמונה חדשה והגיוון מוגבל לחזרתיות הפנימית",
      "חוסר יכולת לעבוד על תמונות מתחת ל-256×256",
      "רגישות גבוהה לרעש בקלט"
    ],
    "correctAnswerIndex": 1,
    "explanation": "צריך לאמן מודל מהתחלה לכל תמונה, והווריאציות נשענות רק על התבניות החוזרות בתמונה. :contentReference[oaicite:12]{index=12}:contentReference[oaicite:13]{index=13}"
  },
  {
    "type": "mc",
    "question": "איזו בעיה מרכזית ב-StyleGAN1 מודולציה + Demodulation ב-StyleGAN2 פותרת?",
    "options": [
      "חוסר שליטה ברמת הרזולוציה",
      "ארטיפקטים כמו קווים דמויי קופסה בתמונות",
      "Mode Collapse קבוע",
      "צריכת זיכרון גבוהה ב-Discriminator"
    ],
    "correctAnswerIndex": 1,
    "explanation": "האיזון בין הערוצים מפחית קווים ותבניות מלאכותיות שהופיעו ב-StyleGAN1. :contentReference[oaicite:14]{index=14}:contentReference[oaicite:15]{index=15}"
  },
  {
    "type": "mc",
    "question": "GANSpace מגלה כיווני עריכה ב-StyleGAN על-ידי…",
    "options": [
      "שימוש ב-CLIP Loss וטקסט",
      "ביצוע PCA על האקטיבציות הפנימיות של הרשת",
      "אימון Discriminator נוסף",
      "השוואת תמונות אמיתיות לפלטי הגנרטור"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ניתוח רכיבי PCA חושף כיוונים שמשנים תכונות כמו תאורה או הבעה. :contentReference[oaicite:16]{index=16}:contentReference[oaicite:17]{index=17}"
  },
  {
    "type": "mc",
    "question": "StyleCLIP – Latent Optimization משנה תמונה כך שתתאים לטקסט על-ידי…",
    "options": [
      "עדכון משקולות הגנרטור מאפס",
      "Gradient Descent ישירות על קוד הלטנט של התמונה",
      "שימוש ב-Random Noise משתנה בכל צעד",
      "החלפת ה-Discriminator במודל CLIP"
    ],
    "correctAnswerIndex": 1,
    "explanation": "מבצעים אופטימיזציה על הלטנט כדי למזער את CLIP Loss לעבר הטקסט. :contentReference[oaicite:18]{index=18}:contentReference[oaicite:19]{index=19}"
  },
  {
    "type": "mc",
    "question": "למה Latent Mapper של StyleCLIP נחשב מהיר יותר אך פחות מדויק מ-Latent Optimization?",
    "options": [
      "הוא דל בפרמטרים ולכן סובל ממוד קאלפס",
      "הוא רשת feed-forward קבועה שאינה מותאמת לתמונה הספציפית",
      "הוא מחליף את CLIP בשכבת Softmax בלבד",
      "הוא משתמש רק במרחב Z ולא ב-W או S"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ה-Mapper פועל בפס יחיד ללא התאמה ספציפית ולכן מהיר אך גנרי." 
  },
  {
    "type": "open",
    "question": "הסבר בקצרה כיצד Entropy Loss תורם לבינאריות של המסכה ב-Double-DIP.",
    "correctAnswerText": "Entropy Loss מעניש פיקסלים עם ערכי ביניים במסכה, ובכך דוחף אותם לערכים 0 או 1. התוצאה היא מסכה חדה ומופרדת המבהירה אילו פיקסלים שייכים לכל רכיב.",
    "explanation": "בינאריות חשובה כדי שכל רשת DIP תלמד חלק ייחודי ללא חפיפה. :contentReference[oaicite:20]{index=20}:contentReference[oaicite:21]{index=21}"
  },
  {
    "type": "open",
    "question": "מדוע Early Stopping חיוני ב-Deep Image Prior כאשר מבצעים denoising?",
    "correctAnswerText": "אם ממשיכים לאמן מעבר לנקודת האיזון, הרשת תתחיל לשחזר גם את רעש התמונה. עצירה מוקדמת מאפשרת לשחזר את המבנה בלבד ולהשאיר את הרעש מחוץ לפלט.",
    "explanation": "הרשת לומדת מן הקל אל הכבד – קודם מבנה, אחר כך רעש – ולכן צריך לעצור בזמן. :contentReference[oaicite:22]{index=22}:contentReference[oaicite:23]{index=23}"
  },
  {
    "type": "open",
    "question": "תאר את פירמידת האימון של SinGAN ולמה היא מפחיתה Mode Collapse.",
    "correctAnswerText": "האימון מתחיל בגרסה זעירה של התמונה; GAN קטן לומד מבנה גלובלי. הפלט שלו מזין את הרמה הבאה ברזולוציה גבוהה יותר, שבה נוסף פרטי טקסטורה. רמות אלה מאומנות אחת-אחת, כך שהגנרטור אינו צריך לפתור בבת אחת יצירת תמונה מלאה, מה שמפחית את הסיכוי לקרוס לוריאציות זהות.",
    "explanation": "חלוקה לרמות מורידה מורכבות בכל שלב ומשמרת גיוון. :contentReference[oaicite:24]{index=24}:contentReference[oaicite:25]{index=25}"
  },
  {
    "type": "open",
    "question": "כיצד Modulation + Demodulation שומר על איזון ערוצים ב-StyleGAN2?",
    "correctAnswerText": "ה-modulation מכפיל כל פילטר בסקלת סגנון ותפור לפי \( w \); demodulation מנרמל את הפילטרים חזרה כך שלכל ערוץ תהיה עוצמה דומה, וכך נמנעים קפיצות ערכים שיוצרות ארטיפקטים.",
    "explanation": "הנירמול מצמצם סטיות ומפחית קווים מלאכותיים. :contentReference[oaicite:26]{index=26}:contentReference[oaicite:27]{index=27}"
  },
  {
    "type": "open",
    "question": "מדוע כיווני עריכה שנמצאו ב-GANSpace נחשבים ללא-מונחים (unsupervised)?",
    "correctAnswerText": "GANSpace מבצע PCA על האקטיבציות מבלי להשתמש בשום תווית; הכיוונים הסמנטיים נחשפים אוטומטית כתוצאה מהשונות הגבוהה בנתונים.",
    "explanation": "השיטה לא דורשת תיאור טקסטואלי או תגיות ידניות. :contentReference[oaicite:28]{index=28}:contentReference[oaicite:29]{index=29}"
  }
]
