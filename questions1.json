[
  {
    "type": "mc",
    "question": "מהי המשימה שמגדירים כ-Image-to-Image Translation?",
    "options": [
      "המרת וידאו לרצף של תמונות רציפות בזמן",
      "מיפוי תמונה מתחום מקור לתחום יעד תוך שמירת משמעות ומבנה",
      "זיהוי אובייקטים בתמונה באמצעות רשת ייעודית",
      "דחיסת תמונות באובדן מידע מינימלי"
    ],
    "correctAnswerIndex": 1,
    "explanation": "בתרגום תמונה-לתמונה רוצים לשנות סגנון או מאפיינים של התמונה ועדיין לשמור על התוכן והגאומטריה המקוריים."
  },
  {
    "type": "mc",
    "question": "מהו ההבדל העיקרי בין Supervised ל-Unsupervised Image Translation?",
    "options": [
      "ב-Supervised יש זוגות תמונות תואמים וב-Unsupervised אין התאמה ישירה",
      "ב-Supervised מאמנים GAN בלבד וב-Unsupervised מאמנים AutoEncoder בלבד",
      "ב-Supervised משתמשים רק בפונקציית L2 וב-Unsupervised רק ב-L1",
      "ב-Supervised עובדים ללא Data Augmentation וב-Unsupervised עם Augmentation אינטנסיבי"
    ],
    "correctAnswerIndex": 0,
    "explanation": "גישה מונחית נשענת על זוגות קלט-פלט ידועים, בעוד שבגישה בלתי-מונחית יש רק אוספים נפרדים משני תחומים."
  },
  {
    "type": "mc",
    "question": "מדוע מוסיף מודל U-Net קישורי Skip בין Encoder ל-Decoder?",
    "options": [
      "להגדיל את עומק הרשת ללא שינוי בזיכרון",
      "לשמר מידע מרחבי שאובד בדחיסה ולאפשר שחזור פרטים מדויקים",
      "לאכוף רגולריזציה על משקולות ה-Decoder בלבד",
      "להחליף צורך ב-Batch Normalization בשכבות העמוקות"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ה-Skip Connections מחזירים מפות אקטיבציה ברזולוציה גבוהה, כך שה-Decoder משחזר מיקום וטקסטורה שאבדו."
  },
  {
    "type": "mc",
    "question": "למה פונקציות L1/L2 בתרגום תמונה-לתמונה נוטות ליצור תוצאות מטושטשות?",
    "options": [
      "הן גורמות לרשת להתמקד רק בפרטים עתירי-תדר",
      "הן מחשבות ממוצע פיקסל-לפיקסל ולכן מתכנסות לפתרון ממוצע של כל האפשרויות התקפות",
      "הן אינן גזירות ולכן הגרדיאנט מתאפס בשכבות מוקדמות",
      "הן מניחות שכל התמונות בסולם אפור ולא בצבע מלא"
    ],
    "correctAnswerIndex": 1,
    "explanation": "כאשר קיימים פתרונות רבים, ממוצע ליניארי של פיקסלים מוביל לטשטוש במקום לבחירת חדות ייחודית."
  },
  {
    "type": "mc",
    "question": "Perceptual Loss מודד הבדלים בין תמונות על ידי…",
    "options": [
      "השוואת היסטוגרם צבע גלובלי בכל תמונה ישירות",
      "חישוב פער בין מפות אקטיבציה פנימיות של רשת מאומנת מראש כמו VGG",
      "מדידת ממוצע ערכי ה-RGB בכל שכבת קונבולוציה",
      "ספירת מספר האובייקטים שזוהו בכל תמונה"
    ],
    "correctAnswerIndex": 1,
    "explanation": "במקום להשוות פיקסלים, מחשבים מרחק ב-feature space של רשת סיווג, המתיישר עם תפיסת חדות אנושית."
  },
  {
    "type": "mc",
    "question": "ב-Pix2Pix הן ה-Generator והן ה-Discriminator מקבלים את תמונת הקלט כתנאי כדי…",
    "options": [
      "להפחית את מספר שכבות ה-GAN לחצי",
      "להבטיח שהפלט קשור ספציפית לקלט ולא רק נראה ריאליסטי כללי",
      "לאפשר אימון ללא פונקציות רגולריזציה נוספות",
      "לאפס את הצורך בלוס מסוג L1"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ה-Discriminator בודק זוג (קלט, פלט) ולכן דורש שה-Generator ישמור התאמה המבנית לקלט."
  },
  {
    "type": "mc",
    "question": "PatchGAN Discriminator ב-Pix2Pix פועל על חלונות קטנים כדי…",
    "options": [
      "ללמוד תדרים נמוכים בלבד",
      "להתמקד בפרטים מקומיים עתירי-תדר ולחסוך פרמטרים",
      "להחליף את הצורך ב-Cycle Consistency",
      "לשלוט בזיכרון מטמון של ה-GPU בזמן תרגום"
    ],
    "correctAnswerIndex": 1,
    "explanation": "בדיקה מקומית (למשל ‎70×70‎) מדגישה טקסטורה וחדות ומאפשרת רשת קטנה ויעילה."
  },
  {
    "type": "mc",
    "question": "באיזה Trade-off מאזנים ב-Pix2Pix בין שני רכיבי הפסד?",
    "options": [
      "בין L2 ל-Dropout כדי לשמר צבעים",
      "בין L1 לשכבות Pooling כדי לשלוט בגודל התמונה",
      "בין L1 להתחייבות Adversarial כדי לשמור מבנה ולשפר חדות",
      "בין KL Divergence ל-FID לצורך יציבות"
    ],
    "correctAnswerIndex": 2,
    "explanation": "L1 שומר על התאמה מבנית; Adversarial מחדד פרטים. משקלי-הפסד קובעים את האיזון."
  },
  {
    "type": "mc",
    "question": "CycleGAN משתמש בשני Generators ושני Discriminators כדי…",
    "options": [
      "להקטין את זמן האימון הכולל בחצי",
      "לאפשר תרגום דו-כיווני בין שני תחומים בלתי-מתואמים",
      "למחוק צורך במערך נתונים גדול",
      "להגביל את המספר הכולל של משקולות ברשת"
    ],
    "correctAnswerIndex": 1,
    "explanation": "כל Generator ממיר כיוון אחד, וה-Cycle Consistency מחייב שחזור חזרה לתמונה המקורית."
  },
  {
    "type": "mc",
    "question": "Cycle Consistency Loss ב-CycleGAN מבטיח ש…",
    "options": [
      "ה-Discriminator לא יראה את תמונת הקלט",
      "המרה הלוך-חזור תשחזר את התמונה המקורית בצורה מינימלית בהפסד",
      "ה-Generator יפיק בדיוק את אותן תמונות בכל איטרציה",
      "ה-PatchGAN יתמקד רק בתדרים נמוכים"
    ],
    "correctAnswerIndex": 1,
    "explanation": "הקריטריון מעודד את הרשת לשמר תוכן וגאומטריה, כי החזרה לתחום המקור חייבת להיות מדויקת."
  },
  {
    "type": "mc",
    "question": "הנחת Shared Latent Space ב-UNIT גורסת ש…",
    "options": [
      "לשני תחומים אין שום תכונה משותפת",
      "קיימת הפצה לטנטית משותפת שאליה ניתן למפות תמונות משני תחומים שונים",
      "כל Encoder פועל במרחב לטנטי נפרד ללא חפיפה",
      "רק אחד מה-Decoders משתמש ב-Discriminator"
    ],
    "correctAnswerIndex": 1,
    "explanation": "המודל מניח שניתן לקודד תמונות משני התחומים ל-z דומה, ואז לפענח כל תחום עם Decoder ייעודי."
  },
  {
    "type": "mc",
    "question": "MUNIT מפריד במפורש בין…",
    "options": [
      "גרדיאנטים חיוביים ושליליים בכל שכבה",
      "קוד תוכן יציב וקוד סגנון ניתן להחלפה",
      "ישויות GAN ודאטה אמיתית",
      "תדרים נמוכים ותדרים בינוניים בלבד"
    ],
    "correctAnswerIndex": 1,
    "explanation": "הפרדה זו מאפשרת דגימת סגנונות שונים עבור אותו תוכן וכך הפקת מגוון תרגומים."
  },
  {
    "type": "mc",
    "question": "ב-MUNIT שלב Cross-Domain Translation מבוצע על ידי…",
    "options": [
      "שילוב קוד התוכן המקורי עם קוד סגנון מדומיין מהתחום היעד",
      "החזרת פיקסלים זהים מהתמונה המקורית אל הפלט",
      "החלפת Encoder ו-Decoder בין התחומים ללא שינוי קוד",
      "הגדלת רזולוציה לפני כל מעבר תחום"
    ],
    "correctAnswerIndex": 0,
    "explanation": "שומרים את התוכן ומזריקים סגנון חדש כדי ליצור גרסה שייכת לתחום היעד אך עם אותו מבנה."
  },
  {
    "type": "mc",
    "question": "גישת Image Analogies מבצעת התאמת סגנון באמצעות…",
    "options": [
      "חישוב מאפייני Gram Matrix עמוק",
      "התאמת טלאים (Patch Matching) בין זוג תמונות דוגמה",
      "GAN מותנה עם U-Net בפלט",
      "הקטנת צבעים למרחב YIQ בלבד"
    ],
    "correctAnswerIndex": 1,
    "explanation": "השיטה הקלאסית עוד לפני רשתות, מוצאת טלאים דומים ומעבירה עיבוד דומה מתמונה A לתמונה B."
  },
  {
    "type": "mc",
    "question": "בשיטת Gatys להעברת סגנון, הסגנון מיוצג על-ידי…",
    "options": [
      "שכבות Fully Connected ברשת",
      "מטריצת גרם של מפת האקטיבציות בשכבות רדודות",
      "הפרש פיקסלים מרובע בין שתי תמונות",
      "וקטור יחיד במרחב הלטנטי של GAN"
    ],
    "correctAnswerIndex": 1,
    "explanation": "קורלציית פילטרים (Gram) תופסת טקסטורה וצבע ללא תלות במיקום."
  },
  {
    "type": "mc",
    "question": "בתהליך Style Transfer של Gatys העדכון מתבצע על…",
    "options": [
      "משקולות הרשת המאומנת מראש",
      "פיקסלי התמונה החדשה עצמה",
      "קוד הלטנט ברשת AutoEncoder",
      "משקולות ה-Discriminator בלבד"
    ],
    "correctAnswerIndex": 1,
    "explanation": "התמונה החדשה היא הפרמטר האופטימיזציוני; משקלי VGG נשארים קבועים."
  },
  {
    "type": "mc",
    "question": "Alpha ובטא ב-Style Transfer שולטים ב…",
    "options": [
      "קצב למידה ומספר איטרציות",
      "משקל יחסי בין הפסד תוכן לפסד סגנון",
      "גודל חלונות ה-PatchGAN",
      "כמות הזוגות בהנחת Shared Latent Space"
    ],
    "correctAnswerIndex": 1,
    "explanation": "בחירה באלפא גדול מדגישה תוכן; בטא גדול מדגישה סגנון."
  },
  {
    "type": "mc",
    "question": "PatchGAN אופייני משתמש בגודל ‎70×70‎ כדי…",
    "options": [
      "לכנות את כל התמונה כ-Patch יחיד",
      "לכסות פרטים עתירי-תדר ברזלוציה מוקומית אפקטיבית",
      "להבטיח שה-GAN יתכנס תמיד אחרי 70 אפוקים",
      "להפחית את הצורך ב-Cycle Consistency Loss"
    ],
    "correctAnswerIndex": 1,
    "explanation": "חלון כזה מאזן בין טקסטורה מקומית למספיק הקשר, מה שמוכיח יעילות בתרגום."
  },
  {
    "type": "mc",
    "question": "איזה רכיב בפונקציית Loss של Pix2Pix אחראי לחדות הפרטים?",
    "options": [
      "L1 המבוסס פיקסל-לפיקסל",
      "Adversarial Loss מול ה-Discriminator",
      "Smoothness Constraint על גרדיאנט מרחבי",
      "KL Divergence אל הפצה סטנדרטית"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ה-Discriminator מעניש טקסטורה מלאכותית ומעודד יצירת תדרים גבוהים ריאליסטיים."
  },
  {
    "type": "mc",
    "question": "ב-Style Transfer, שכבות עמוקות יותר ברשת VGG משמשות למדידת…",
    "options": [
      "סגנון בלבד כי הן רגישות לטקסטורה עדינה",
      "תוכן ומבנה סמנטי של האובייקטים בתמונה",
      "הפרשי בהירות בין פיקסלים סמוכים",
      "שכיחות רעש גאוסי דק"
    ],
    "correctAnswerIndex": 1,
    "explanation": "השכבות הגבוהות למדו ייצוגים ברמת אובייקט, לכן המרחק בהן משקף הבדל בתוכן."
  },
  {
    "type": "mc",
    "question": "חיסרון עיקרי של שיטת Gatys בזמן ריצה הוא…",
    "options": [
      "חייבת חיבור לאינטרנט לאחזור מודל",
      "דורשת אופטימיזציה מחדש עבור כל תמונה, ולכן איטית בזמן אמת",
      "מסיקה רק על תמונות בגודל ‎224×224‎",
      "מחייבת נתוני אימון זוגיים לכל סגנון"
    ],
    "correctAnswerIndex": 1,
    "explanation": "מאחר ולא מאמנים רשת Feed-Forward אלא מבצעים גרדיאנט על הפיקסלים, התהליך ארוך."
  },
  {
    "type": "mc",
    "question": "איזה תדרי-תמונה מטופלים בעיקר על-ידי רכיב L1 ב-Pix2Pix?",
    "options": [
      "תדרים גבוהים בלבד",
      "תדרים נמוכים שמייצגים מבנה גלובלי",
      "תדרי ביניים סביב ‎1 kHz‎",
      "הרכיב לא תלוי בתדר כלל"
    ],
    "correctAnswerIndex": 1,
    "explanation": "השוואת פיקסל-לפיקסל מגיבה בעיקר למבנה ולערכים ממוצעים ולכן פותרת הבדלים בתדירות נמוכה."
  },
  {
    "type": "open",
    "question": "הסבר בקצרה כיצד Skip Connections ב-U-Net משפרים תרגום תמונה-לתמונה.",
    "correctAnswerText": "ה-Skip Connections מעבירים מפות אקטיבציה ברזולוציה גבוהה ישירות ל-Decoder, כך שה-Decoder מקבל מידע מרחבי מדויק שאבד בכיווץ, ומשחזר קצוות ומבנים קטנים ביתר חדות.",
    "explanation": "ללא החיבור, ה-latent הדחוס מאבד מיקום; צירוף הדרך הקצרה מחזיר את הפרטים בזמן ה-Upsampling."
  },
  {
    "type": "open",
    "question": "מדוע PatchGAN Discriminator חסכוני יותר מדיסקרימינטור גלובלי מלא?",
    "correctAnswerText": "ה-PatchGAN בודק בלוקים קטנים ולכן צריך הרבה פחות פילטרים ושכבות כדי לכסות את כל התמונה; אותו מסנן מוחל קונבולוציונית על כל מקום, מה שחוסך משקולות וזיכרון ומאפשר טיפול בתמונות גדולות ללא הגדלת הרשת.",
    "explanation": "על-ידי חלון נייח, הגודל של הרשת אינו תלוי ברזולוציה של התמונה אלא בגודל ה-Patch."
  },
  {
    "type": "open",
    "question": "מהו היתרון של שילוב Perceptual Loss עם L1 בתרגום מפוקח?",
    "correctAnswerText": "Perceptual Loss דואג שהפלט יהיה דומה אנושית במרחב-פיצ'רים, ול-L1 מבטיח התאמה במיקום פיקסלים. השילוב מונע טשטוש וגם שומר על פרטים מבניים מדויקים בו-זמנית.",
    "explanation": "כל רכיב מפצה על חסרונות השני: L1 לבדו מטשטש, Perceptual לבדו עלול שלא לשמר יישור גאומטרי."
  },
  {
    "type": "open",
    "question": "כיצד Cycle Consistency Loss עוזר ב-Unsupervised Translation לשמור על זהות אובייקטים?",
    "correctAnswerText": "אם תמונה מומרת מתחום A לתחום B ואז חזרה, הדרישה שהשחזור יהיה זהה למקור מאלצת את הרשת לא למחוק או לשנות פרטי תוכן חיוניים, ולכן זהותו ומיקומו של כל אובייקט נשמרים לאורך שני המעברים.",
    "explanation": "ללא אילוץ זה, ה-Generator עלול להפיק פלט סגנוני תקין אך לא קשור לתמונה המקורית."
  },
  {
    "type": "open",
    "question": "הסבר בקצרה את הנחת Shared Latent Space במודל UNIT.",
    "correctAnswerText": "UNIT מניח שקיימת הפצה סמויה משותפת שבה תמונות משני התחומים יכולות לקבל ייצוג זהה; לכן ניתן לקודד תמונה מכל תחום לאותו z ואז לפענח בעזרת Decoder של התחום השני לקבלת תרגום עקבי.",
    "explanation": "הנחה זו מחליפה צורך בזוגות נתונים תואמים כי היא מגדירה \"נקודת מפגש\" סמנטית לשני התחומים."
  },
  {
    "type": "open",
    "question": "כיצד MUNIT מאפשר יצירת מספר בלתי-מוגבל של תרגומים עבור אותה תמונה?",
    "correctAnswerText": "MUNIT שומר על קוד התוכן הקבוע ומדגם בכל פעם קוד סגנון חדש מההתפלגות של תחום היעד; ערבוב התוכן עם סגנונות שונים יוצר וריאציות רבות שאין להן גבול תאורטי.",
    "explanation": "ההפרדה המפורשת בין תוכן וסגנון מאפשרת קומבינציות רבות של אותו מבנה עם סגנונות משתנים."
  },
  {
    "type": "open",
    "question": "מה התפקיד של Gram Matrix בחישוב Style Loss בשיטת Gatys?",
    "correctAnswerText": "Gram Matrix מודדת קורלציות בין פילטרים בשכבה, ולכן מתאר אילו תכונות ויזואליות מופיעות יחד. התאמת הגרמים בין תמונת הסגנון לתמונה החדשה מבטיחה שהטקסטורה, הצבע והמרקם יועתקו ללא קשר למיקום.",
    "explanation": "קורלציה תופסת סטטיסטיקה גלובלית של תבניות, מה שמספיק לשחזור \"תחושה\" סגנונית."
  },
  {
    "type": "open",
    "question": "מדוע Alpha גבוה ובטא נמוך מעניקים תוצאה עם פחות סגנון ויותר תוכן ב-Style Transfer?",
    "correctAnswerText": "Alpha שולט במשקל Loss התוכן; ערך גבוה גורם לאופטימיזציה להעדיף שימור מבנה. בטא נמוך מפחית חשיבות הסגנון ולכן הסגנון מוטמע בעדינות בלבד.",
    "explanation": "היחס Alpha:Beta מכתיב איזו שגיאה \"יקרה\" יותר באופטימיזציה על הפיקסלים."
  },
  {
    "type": "open",
    "question": "תאר תופעת Blurriness ב-Pix2Pix כשמגדילים את משקל L1 יתר על המידה.",
    "correctAnswerText": "כאשר L1 דומיננטי, המודל נענש על כל סטייה פיקסלית ולכן מתכנס לפתרון ממוצע של כל דוגמאות היעד האפשריות; הממוצע של סגנונות רבים הוא מטושטש וחסר פרטים חדים.",
    "explanation": "Adversarial Loss מתמקד בתדרים גבוהים שה-L1 מתעלם מהם; בלעדיו איכות הטקסטורה נפגעת."
  },
  {
    "type": "open",
    "question": "הסבר כיצד PatchGAN מקל על תרגום תמונות ברזולוציה גבוהה מבלי להגדיל את הדיסקרימינטור.",
    "correctAnswerText": "ה-Discriminator הוא רשת קונבולוציה קטנה שמופעלת לגמרי קונבולוציונית על כל מיקום בתמונה, ולכן מספר הפרמטרים קבוע. גודל התמונה משפיע רק על מספר ה-Patches שנבדקים אך לא על גודל הרשת.",
    "explanation": "השימוש בחלון מקומי וב-Stride מאפשר סריקה יעילה של תמונות גדולות ללא גדילה בזיכרון."
  },
  {
    "type": "open",
    "question": "מדוע שיטת העברת סגנון באמצעות רשתות נוירונים אינה מתאימה לשימוש בזמן-אמת באפליקציות ניידות?",
    "correctAnswerText": "השיטה מבצעת אופטימיזציה ישירה על פיקסלי התמונה החדשה, תהליך שדורש חישוב מחדש לכל תמונה ולכן אינו מתאים לזמן אמת",
    "explanation": "במקום לעדכן את משקלי הרשת כמו באימון רגיל, השיטה מבצעת Gradient Descent על פיקסלים של תמונה רנדומלית עד שהיא תשלב את התוכן והסגנון הרצויים. תהליך זה כולל חישובים רבים עבור כל תמונה מחדש ואינו יעיל למכשירים עם משאבים מוגבלים או ליישומים בזמן אמתץ לסיכום השיטה מאפשרת שליטה מדויקת על איזון בין תוכן לסגנון, אך דורשת חישוב מחדש לכל תמונה ולכן אינה מתאימה לעבודה בזמן אמת"
  }
]
