[
  {
    "type": "mc",
    "question": "איזו בעיה מרכזית פותרת StyleGAN-NADA?",
    "options": [
      "הסרת רעש סטוכסטי משכבות הרעש של StyleGAN",
      "התאמת הגנרטור לדומיין חדש בלי תמונות מאותו דומיין",
      "שיפור חדות הפלט בעזרת Discriminator נוסף",
      "המרת תמונות אמיתיות לקוד W+ במהירות"
    ],
    "correctAnswerIndex": 1,
    "explanation": "השיטה מקפיאה עותק מקורי של הגנרטור ומדייקת עותק מאומן כך שיצייר קטגוריה שלא הופיעה באימון, מבלי להחזיק דאטה של אותה קטגוריה"
  },
  {
    "type": "mc",
    "question": "למה אופטימיזציה ישירה של ה-w המקורי לא מספיקה כדי לייצר חתול ממודל שחונך על כלבים?",
    "options": [
      "כי מודל CLIP אינו חלק מהזרימה קדימה",
      "כיוון שהמרחב W חסום למשקולות קפואות וגיוון נמוך",
      "משום שהגנרטור כלל לא מכיר חתולים ולכן כל וקטור w יישאר בדומיין הכלבים",
      "בגלל ש-w תמיד עובר נירמול Demodulation שמגביל סגנון"
    ],
    "correctAnswerIndex": 2,
    "explanation": "המודל לא 'יודע' ליצור חתול; הזזת w בלבד תסתובב בתוך אזורי כלביים של ההתפלגות"
  },
  {
    "type": "mc",
    "question": "באימון StyleGAN-NADA איזה רכיב קפוא (frozen)?",
    "options": [
      "ה-Discriminator של StyleGAN",
      "עותק מקורי של הגנרטור (G_frozen)",
      "רשת CLIP הטקסטואלית בלבד",
      "כל שכבות ה-Mapping Network"
    ],
    "correctAnswerIndex": 1,
    "explanation": "משתמשים בשני גנרטורים: G_frozen נשאר ללא עדכון ומייצר את התמונה בדומיין המקורי לצורך חישוב הכיוון ב-CLIP"
  },
  {
    "type": "mc",
    "question": "מהו היתרון הבולט של Inversion מבוסס-Encoder (למשל pSp) לעומת Latent Optimization?",
    "options": [
      "דיוק גבוה יותר במחיר חיפוש איטרטיבי ארוך",
      "מהירות רבה בזכות Pass יחיד קדימה על חשבון דיוק קטן יותר",
      "שמירה מוחלטת על זהות הפנים ללא Fine-Tuning",
      "יכולת לעבוד בדומיין חדש בלי אימון נוסף"
    ],
    "correctAnswerIndex": 1,
    "explanation": "Encoder מאומן מראש מחזיר מיד וקטור W+ ולכן ההיפוך מיידי, אך השחזור פחות מדויק יחסית לאופטימיזציה איטרטיבית"
  },
  {
    "type": "mc",
    "question": "Pivotal Tuning Inversion (PTI) משפר דיוק שחזור ע\"י…",
    "options": [
      "אימון Discriminator נוסף לרזולוציה גבוהה",
      "טאונינג נקודתי של משקולות הגנרטור סביב תמונה מסוימת",
      "החלפת AdaIN במנגנון Mod/Demod",
      "שימוש בקוד לטנטי Z במקום W+"
    ],
    "correctAnswerIndex": 1,
    "explanation": "PTI עושה Fine-Tuning קל למשקולות על בסיס הפלט הראשוני כדי לצמצם שגיאות לוקאליות של התמונה המסוימת"
  },
  {
    "type": "mc",
    "question": "HyperStyle מוסיף לרשת הגנרטור…",
    "options": [
      "שכבות Self-Attention גלובליות",
      "רשת Δ קטנה שמניבה תיקון משקולות מותאם לתמונה",
      "קוד רעש דינמי פר-פיקסל",
      "Decoder נוסף לרזולוציה גבוהה"
    ],
    "correctAnswerIndex": 1,
    "explanation": "HyperStyle מאמן רשת קטנה שמנבאת דלתא למשקולות, וכך משיג שחזור מדויק מבלי לעבור Fine-Tuning ארוך לכל תמונה"
  },
  {
    "type": "mc",
    "question": "מדוע משתמשים במרחב W+ ולא ב-W באינברסיה של תמונות?",
    "options": [
      "כי W+ מותאם ל-CLIP ומחזיר טקסט חופשי",
      "כדי לאפשר וקטור שונה בכל שכבה לשחזר פרטים עדינים",
      "כיוון שהוא צורך פחות זיכרון GPU",
      "מפני שהוא מונע Demodulation בשכבות"
    ],
    "correctAnswerIndex": 1,
    "explanation": "הגדלת דרגת החופש (וקטור נפרד לכל שכבה) מאפשרת תיקון גם במבנה וגם בטקסטורה לשחזור צמוד למקור"
  },
  {
    "type": "mc",
    "question": "איזה שימוש הדגימה ההרצאה ל-Encoder Inversion מעבר ל-\"Invert & Edit\"?",
    "options": [
      "In-painting ללא מסכה",
      "Edge-Map → Image ליצירת תמונות ריאליסטיות מקווי מתאר",
      "דחיסת תמונה לארכיון Codebook",
      "שחזור עומק (Depth) בהפרדה"
    ],
    "correctAnswerIndex": 1,
    "explanation": "כאשר מאמנים את ה-Encoder על זוגות קווי מתאר/תמונה, אפשר להפוך סקיצה לתמונה פוטוריאליסטית בזכות כוחו של StyleGAN"
  },
  {
    "type": "mc",
    "question": "כיצד מפורקת הסתברות התמונה במודל אוטורגרסיבי?",
    "options": [
      "p(x)=Σp(x_i)",
      "p(x)=Π p(x_i | x_{<i})",
      "p(x)=max p(x_i)",
      "p(x)=Mean p(x_i)"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ה-AR מחלק את הקלט לרצף וּמודל את ההסתברות המותנית של כל חלק על קודמיו, כלומר מכפלת תנאים סדרתית"
  },
  {
    "type": "mc",
    "question": "PixelCNN משתמש ב-Masked Convolution בעיקר כדי…",
    "options": [
      "למנוע התפוצצות גרדיאנט ברזולוציה גבוהה",
      "לא לאפשר לפיקסל הנוכחי לראות פיקסלים עתידיים בסריקה",
      "להקטין את מספר הפרמטרים פי ארבעה",
      "לשלב Self-Attention חישובי"
    ],
    "correctAnswerIndex": 1,
    "explanation": "אפסים במסנן מבטיחים שהרשת נשענת רק על פיקסלים שכבר נוצרו וכך משמרת את הסדר האוטורגרסיבי התקף"
  },
  {
    "type": "mc",
    "question": "מגבלה בולטת של PixelCNN שהוזכרה בהרצאה היא…",
    "options": [
      "דגימות מטושטשות ואיטיות מאוד ברזולוציות גבוהות",
      "קושי בלמידה מבוססת CLIP",
      "חוסר יכולת לעבוד עם קוד דיסקרטי",
      "הישענות על תוויות מפוקחות"
    ],
    "correctAnswerIndex": 0,
    "explanation": "המודל יוצר תמונות 32×32-64×64 לא חדות ודגימה פיקסל-אחר-פיקסל גוזלת זמן רב"
  },
  {
    "type": "mc",
    "question": "VQ-VAE מציג ייצוג דיסקרטי בעזרת…",
    "options": [
      "קואנטיזציה של וקטורי הפיצ'ר לקודבוק סופי",
      "החלת Masked Convolution בכל שכבה",
      "Demodulation גלובלי על וקטורים",
      "קרוס-אטנשן בין פאטצ'ים"
    ],
    "correctAnswerIndex": 0,
    "explanation": "Encoder מחפש לכל וקטור את הערך הקרוב ביותר ב-Codebook וכך דוחס את התמונה למפת סמלים קומפקטית"
  },
  {
    "type": "mc",
    "question": "מדוע שחזורי VQ-VAE נוטים להיות מטושטשים?",
    "options": [
      "ה-Decoder חסר שכבות Upsample",
      "אין Loss אדברסריאלי ואיבוד קשרים גלובליים",
      "שימוש בדלתא משקולות מקומיות בלבד",
      "ה-Codebook קטן מדי ומאלץ חזרתיות"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ללא Discriminator נוסף התמונות נשענות רק על Loss שחזור ולכן מאבדות חדות ופרטים גלובליים"
  },
  {
    "type": "mc",
    "question": "VQ-GAN מוסיף ל-VQ-VAE שני מרכיבים עיקריים: Discriminator ו-…",
    "options": [
      "Transformer הלומד את התפלגות הקודים",
      "Masked Conv נוסף בלייר האחרון",
      "שכבת Modulation-Demodulation",
      "רשת Δ לשחזור פרטים"
    ],
    "correctAnswerIndex": 0,
    "explanation": "GAN-Loss משחיז תמונה ו-Transformer על רצף הקודים לוכד קשרים רחוקים לשיפור קוהרנטיות"
  },
  {
    "type": "mc",
    "question": "Self-Attention במודל אוטורגרסיבי של VQ-GAN מאפשר…",
    "options": [
      "חסכון בזיכרון ליניארי לגודל הקלט",
      "למידת קשרים גלובליים בין אזורים רחוקים בתמונה",
      "הפחתת צורך ב-Codebook",
      "ביטול Masked Convolution"
    ],
    "correctAnswerIndex": 1,
    "explanation": "כל פיקסל 'שואל' על אחרים דרך Q,K,V ומקבל ייצוג עשיר המחבר חלקים מרוחקים של התמונה"
  },
  {
    "type": "mc",
    "question": "מה החיסרון העיקרי של Self-Attention שהודגש?",
    "options": [
      "אובדן חזרה פנימית בתמונה",
      "מורכבות חישובית ריבועית בגודל הקלט",
      "בעיית Mode Collapse מתמשכת",
      "רגישות גבוהה ללמידת יתר"
    ],
    "correctAnswerIndex": 1,
    "explanation": "לכל שכבת Attention עלות O(n²), מה שהופך אותה יקרה במיוחד לתמונות גדולות"
  },
  {
    "type": "mc",
    "question": "היררכיית Top/Bottom ב-VQ-VAE-2 משמשת ל…",
    "options": [
      "הפרדת מבנה גלובלי מפרטים עדינים לשיפור רזולוציה",
      "דילול משקלים לחיסכון בזיכרון",
      "למידת קוד לטנט רציף",
      "ביטול צורך ב-Discriminator"
    ],
    "correctAnswerIndex": 0,
    "explanation": "קודם מקודדים את השלד הכללי בשכבת Top, אחר-כך מוסיפים חדות דרך Bottom וכך שומרים גם איכות וגם דחיסה"
  },
  {
    "type": "mc",
    "question": "איזו נוסחת רגולריזציה מוסיפים ב-pSp כדי לייצב את קודי W+?",
    "options": [
      "L1 בין פיקסלים",
      "KL Divergence לנורמלית",
      "Distance Loss אל הקוד הממוצע במרחב W",
      "Orthogonality Loss על משקולות"
    ],
    "correctAnswerIndex": 2,
    "explanation": "Regularization מושך את הקוד לכיוון μ_W ומונע חריגה לאזורים שבהם הגנרטור מפיק תוצאות"
  },
  {
    "type": "mc",
    "question": "ב-HyperStyle, רשת ה-Δ מאומנת לחזות…",
    "options": [
      "שינוי בקוד w",
      "תיקון משקולות ברמת פילטרים לגנרטור",
      "מסכת Attention על שכבות",
      "דחיסת קוד Z לרצף קצר"
    ],
    "correctAnswerIndex": 1,
    "explanation": "ה-Δ מחזיר וקטור תיקונים שמחובר למשקולות המקוריות וכך מותאם לחסרונות המקומיים של שחזור התמונה"
  },
  {
    "type": "mc",
    "question": "ב-PixelCNN מותנה, הווקטור h מייצג…",
    "options": [
      "את קוד ה-Codebook שנבחר",
      "קטגוריה או תווית רצויה המזרימה מידע נוסף",
      "שכבת Noise סטוכסטית",
      "ווקטור Δ משקולות"
    ],
    "correctAnswerIndex": 1,
    "explanation": "בהנחה שרוצים למשל ספרה \"3\", h מספק למודל מידע קטגורי כדי שידגם רק דוגמאות תואמות "
  },
  {
    "type": "mc",
    "question": "מה המאפיין העיקרי של Masked Conv ב-PixelCNN לעומת Conv רגיל?",
    "options": [
      "ליבה בקונבולוציה רדיאלית",
      "איפוס משקלים במסנן שלא שייכים לעבר הפיקסל",
      "הוספת Bias כפול לכל ערוץ",
      "שימוש בקוד Book Lookup"
    ],
    "correctAnswerIndex": 1,
    "explanation": "המסיכה מבטיחה שכל קונבולוציה נשענת רק על פיקסלים שכבר יוצרו ולא על עתידיים, כך נשמרת סיבתיות "
  },
  {
    "type": "mc",
    "question": "Transformer על רצף הקודים ב-VQ-GAN עדיף על PixelCNN כי…",
    "options": [
      "הוא ליניארי בגודל הקלט",
      "הוא לוכד קשרים ארוכי טווח ומשפר קוהרנטיות",
      "הוא אינו דורש שום Mask",
      "הוא מפחית גודל Codebook בחצי"
    ],
    "correctAnswerIndex": 1,
    "explanation": "Self-Attention מקשרת קוד בקצה אחד של התמונה עם אחר בצד השני וכך יוצרת מבנה גלובלי משכנע "
  },
  {
    "type": "mc",
    "question": "ב-StyleGAN-NADA החיווי בין שתי תמונות נמדד ב-CLIP כ…",
    "options": [
      "הפרש וקטורים במרחב הסגנון S",
      "כיוון סמנטי בין אמבדינגי התמונות במרחב CLIP",
      "רמת קשיחות מודולציה ל-w",
      "מרחק L2 ישיר בפיקסלים"
    ],
    "correctAnswerIndex": 1,
    "explanation": "משווים embedding_תמונה_מקור ל-embedding_תמונה_יעד ומיישרים אותו לכיוון בין הטקסטים "
  },
  {
    "type": "mc",
    "question": "מה היתרון של \"Invert-Then-NADA\" (שילוב אינברסיה ו-NADA)?",
    "options": [
      "מאפשר עריכה בדומיין מותאם על תוכן קיים",
      "חוסך את אימון CLIP",
      "מבטל צורך ב-W+",
      "מקטין את גודל Codebook"
    ],
    "correctAnswerIndex": 0,
    "explanation": "הופכים תמונה אמיתית ל-W+, ואז מפעילים גנרטור מותאם-דומיין כדי לערב תוכן מוכר עם סגנון חדש "
  },
  {
    "type": "mc",
    "question": "מדוע דגימה ב-PixelCNN איטית?",
    "options": [
      "ה-Codebook קטן מדי",
      "נדרש חישוב סדרתי פיקסל-אחר-פיקסל",
      "Self-Attention מרובע בזמן",
      "Demodulation בכל שכבה"
    ],
    "correctAnswerIndex": 1,
    "explanation": "כל פיקסל מחושב לאחר הקודמים ולכן אין הקבלה; זה גורם לזמן דגימה ארוך במיוחד "
  },
  {
    "type": "mc",
    "question": "GAN-Loss ב-VQ-GAN מחייב את ה-Decoder…",
    "options": [
      "לסכם פיקסלים ל-1",
      "להפיק תמונות חדות ו“אמיתיות” בעיני Discriminator",
      "לשמור על L2 נמוך בלבד",
      "להפוך Self-Attention לריבועי"
    ],
    "correctAnswerIndex": 1,
    "explanation": "בזכות Discriminator נוסף, הדקודר לומד להחזיר פרטים חדים שנראים אמיתיים למפלה "
  },
  {
    "type": "mc",
    "question": "איזה מנגנון שומר על קשרים ארוכי-טווח במודל Transformer אך דורש משאבים רבים?",
    "options": [
      "Skip-Connections",
      "Self-Attention",
      "Masked Conv",
      "Batch-Norm"
    ],
    "correctAnswerIndex": 1,
    "explanation": "Self-Attention מצריך חישוב מטריצה n×n ולכן יקר אולם מוסיף הבנה גלובלית "
  },
  {
    "type": "mc",
    "question": "ב-HyperStyle, לאחר השחזור ניתן עדיין להשתמש בכיווני עריכה שנלמדו מראש כי…",
    "options": [
      "ה-Δ משנה רק את ה-Mapping Network",
      "התיקונים קטנים ומשמרים את הגאומטריה של מרחב העריכה",
      "הוא מבטל רעש סטוכסטי בין שכבות",
      "הוא מחליף CLIP בתוויות מפוקחות"
    ],
    "correctAnswerIndex": 1,
    "explanation": "דלתא קטנה מיישרת את הפלט אך לא מעוותת את הכיוונים הסמנטיים המקוריים של הגנרטור "
  },
  {
    "type": "mc",
    "question": "מהו תפקיד ה-Codebook ב-VQ-VAE?",
    "options": [
      "לאכוף רגולריזציה L2 על Encoder",
      "לאפשר קוונטיזציה של פיצ'רים לווקטורים סופיים ולצמצם ממד",
      "להגדיל חדות בעזרת GAN-Loss",
      "לייצר קשר בין פיקסלים סמוכים"
    ],
    "correctAnswerIndex": 1,
    "explanation": "כל וקטור פיצ'ר מוצמד לכניסה הקרובה ביותר בקודבוק, כך שהיצוג נעשה דיסקרטי ודחוס "
  },
  {
    "type": "mc",
    "question": "למה Transformer ברצף קודים איננו ליניארי בגודל התמונה?",
    "options": [
      "בגלל קוונטיזציה",
      "מפני שמטריצת QK^T היא מסדר n×n",
      "ה-Codebook קטן מדי",
      "Demodulation מוסיף מורכבות"
    ],
    "correctAnswerIndex": 1,
    "explanation": "Self-Attention מחשב את הדמיון בין כל זוג קודים ולכן העלות חישובית ריבועית במספר הקוד n "
  },
  {
    "type": "open",
    "question": "תאר בקצרה את התהליך המרכזי של StyleGAN-NADA.",
    "correctAnswerText": "מעתיקים את הגנרטור, מקפיאים את המקור, ומאמנים את העותק כך שכיוון השינוי בין תמונת-מקור לתמונת-יעד (ב-CLIP) יהיה מקביל לכיוון שנגזר מזוג טקסטים. כך לומדים לעבור לדומיין חדש בלי דאטה מתאים.",
    "explanation": "השוואת כיוונים ב-CLIP מדריכה את המשקולות להתאים דומיין חדש תוך שמירה על מבנה לטנטי "
  },
  {
    "type": "open",
    "question": "למה אופטימיזציה של w בלבד נכשלת כשמנסים לרנדר חתול בגנרטור כלבים?",
    "correctAnswerText": "ה-w שולט רק בתוכן שקיים בדומיין הלמידה. אם הגנרטור מעולם לא ראה חתולים, כלל מרחב W מיפוי לכלבים ולכן אין כיוון שמוביל לחתול.",
    "explanation": "המודל חסר פונקציית ייסוד לדומיין החתולים ולכן w תקוע בתת-מרחב של כלבים "
  },
  {
    "type": "open",
    "question": "הסבר את המסחר בין דיוק למהירות בין Latent Optimization ל-Encoder Inversion.",
    "correctAnswerText": "Latent Optimization מחפש קוד מותאם בדיוק גבוה אך דורש הרבה איטרציות; Encoder מבצע Pass יחיד ומהיר אך השחזור פחות צמוד משום שהמודל כללי.",
    "explanation": "ה-Encoder מחליף חיפוש איטרטיבי במיפוי ישיר ומקריב חלק מהדיוק "
  },
  {
    "type": "open",
    "question": "איך PTI מחדד שחזור מבלי להרוס כיווני עריכה קיימים?",
    "correctAnswerText": "PTI מתחיל באינברסיה רגילה ואז עושה Fine-Tuning קטן במשקולות הגנרטור סביב אותה תמונה, ולכן נשמרת גאומטריית העריכה אך הפרטים משתפרים.",
    "explanation": "השינויים מזעריים כך שהמרחב הסמנטי לא מעוות "
  },
  {
    "type": "open",
    "question": "מהו Masked Convolution ב-PixelCNN ולמה הוא קריטי?",
    "correctAnswerText": "זהו פילטר קונבולוציה שבו ערכים שמעבירים מידע מפיקסלים עתידיים מאופסים, וכך הפיקסל הנוכחי תלוי רק בעברו ומקיים אוטורגרסיביות.",
    "explanation": "המסיכה מונעת \"דליפת עתיד\" ומבטיחה שהמודל יכבד את סדר הסריקה "
  },
  {
    "type": "open",
    "question": "כיצד VQ-VAE מייצג תמונה כקוד דיסקרטי?",
    "correctAnswerText": "Encoder מפיק מפה של וקטורים רציפים; כל וקטור מוחלף בכניסה הקרובה ביותר ב-Codebook קבוע, ו-Decoder משחזר מהקוד הבדיד.",
    "explanation": "התהליך קוואנטיזציה → ייצוג קומפקטי 
  },
  {
    "type": "open",
    "question": "פרט את שלבי Self-Attention (Q,K,V) כפי שתוארו בהרצאה.",
    "correctAnswerText": "מחשב Q,K,V לכל פיקסל, יוצר מפה QK^T לקבלת משקלי קשב, משקלל אותם עם V, מבצע softmax לקבלת ייצוג חדש שמשלב מידע מכל התמונה.",
    "explanation": "ה-Attention Map מייצר ממוצע משוקלל ששומר יחסים גלובליים "
  },
  {
    "type": "open",
    "question": "למה Transformer משפר קוהרנטיות לעומת PixelCNN ברצף קודים?",
    "correctAnswerText": "Self-Attention מאפשר לכל קוד \"לראות\" קודים רחוקים לכן לומדים קשרים מבניים רחבים, ולא רק תלות לוקאלית כמו ב-Masked Conv.",
    "explanation": "קשרים ארוכי-טווח חשובים לסימטריה ופרטים גלובליים "
  },
  {
    "type": "open",
    "question": "תאר בקצרה את מבנה ההיררכיה Top/Bottom ב-VQ-VAE-2.",
    "correctAnswerText": "שכבת Top מקודדת תכנון גס של הסצנה; Bottom מוסיפה טקסטורות וחדות. הדגימה מתחילה ב-Top ואז משלימה ב-Bottom.",
    "explanation": "הפרדה זו מאזנת איכות מול דחיסה "
  },
  {
    "type": "open",
    "question": "כתוב את נוסחת הפקטוריזציה האוטורגרסיבית והסבר משתנה אחד בה.",
    "correctAnswerText": "p(x)=Π p(x_i | x_{<i}); כאן p(x_i | x_{<i}) היא ההסתברות של החלק הבא ברצף בהתבסס על כל מה שנדגם קודם.",
    "explanation": "המודל לומד תנאי לכל חלק במקום את ההתפלגות המשותפת בבת אחת "
  },
  {
    "type": "open",
    "question": "ציין יישום אחד של אינברסיה והסברו.",
    "correctAnswerText": "Invert & Edit: הופכים צילום לקוד W+ ואז מזיזים אותו בכיוון סמנטי (למשל 'הוסף חיוך') ליצירת גרסה ערוכה באיכות גבוהה.",
    "explanation": "הקוד מאפשר שימוש בכל כיווני העריכה שנלמדו ב-StyleGAN "
  },
  {
    "type": "open",
    "question": "כיצד Loss אדברסריאלי ב-VQ-GAN מחדד תמונה?",
    "correctAnswerText": "Discriminator דורש מה-Decoder לייצר פרטים דקים כדי להטעותו; לכן השחזור הופך חד ומציאותי יותר לעומת Loss שחזור בלבד.",
    "explanation": "GAN-Loss מוסיף לחץ לפלט לראות אמיתי בעיני מפלה "
  },
  {
    "type": "open",
    "question": "מה תפקיד Regularization Loss ב-pSp Encoder?",
    "correctAnswerText": "למשוך את הקודים ש-Encoder מפיק לכיוון הממוצע ב-W ובכך למנוע חריגה לאזורים שבהם הגנרטור מפיק תוצאות לא יציבות.",
    "explanation": "שמירה על קודים 'בטוחים' משפרת יציבות שחזור "
  },
  {
    "type": "open",
    "question": "אילו מגבלות מציג PixelCNN כשעוברים לרזולוציות גבוהות?",
    "correctAnswerText": "הדגימה סיבתית פיקסל-אחר-פיקסל נעשית איטית וקשרי לוקאליות גורמים לתמונות מטושטשות וחסרות קוהרנטיות גלובלית.",
    "explanation": "העדר קשר ארוך טווח והחישוב הסדרתי מגבילים "
  },
  {
    "type": "open",
    "question": "הסבר כיצד דלתא-רשת ב-HyperStyle פועלת.",
    "correctAnswerText": "ה-Δ מקבלת תמונה וכותבת שינוי קטן למשקולות הגנרטור; השינוי מחובר למשקולות המקוריות ומדייק אזורים שבהם השחזור נכשל.",
    "explanation": "כך מתקבלת התאמה מהירה ומקומית בלי לנתק את המודל מהמרחב שלו "
  },
  {
    "type": "open",
    "question": "כיצד CLIP מדריך את האימון ב-StyleGAN-NADA?",
    "correctAnswerText": "חישוב כיוון בין תמונות (G_frozen, G_train) וכיוון בין טקסטים, והמטרה לגרום לכיוונים להחפף במרחב CLIP – זה מפעיל גרדיאנט על משקולות הגנרטור המאומן.",
    "explanation": "CLIP מספק מרחב משותף תמונה-טקסט לחיווי סמנטי "
  },
  {
    "type": "open",
    "question": "מדוע W+ עוזר לשמר פרטים עדינים בעת אינברסיה?",
    "correctAnswerText": "מכיוון שכל שכבה מקבלת וקטור עצמאי, ניתן לכוונן שכבות גבוהות לפרטים (נמשים, טקסטורה) ושכבות נמוכות למבנה – כך משחזרים גם מיקרו-וריאציות.",
    "explanation": "דרגת חופש גבוהה מונעת פשרות על איכות "
  },
  {
    "type": "open",
    "question": "מהו תהליך הקוונטיזציה ב-VQ-VAE ולמה הוא חשוב?",
    "correctAnswerText": "בכל מיקום בוחרים את הווקטור הקרוב ב-Codebook במקום לשמור ערך רציף; כך מקבלים ייצוג דחוס שמקל על מודל גנרטיבי ללמוד התפלגות על קבוצה סופית.",
    "explanation": "הדיסקרטיזציה מאפשרת שימוש ב-AR או Transformer על רצף קצר ובר-השוואה "
  },
  {
    "type": "open",
    "question": "תאר בקצרה מודל Autoregressive מותנה וכיצד הוא שולט על סוג הדגימות.",
    "correctAnswerText": "מכניסים קוד h שמייצג קטגוריה; במהלך האימון החלקים ברצף לומדים גם מהפיקסלים הקודמים וגם מה-h כך שבדגימה ניתן לבחור h ולקבל רק דוגמאות מאותה קטגוריה.",
    "explanation": "הוספת תנאי מיישרת את הדגימה להתחום הרצוי "
  }
]
