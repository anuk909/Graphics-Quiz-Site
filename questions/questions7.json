[
  {
    "type": "mc",
    "question": "מהי המטרה העיקרית של פרסונליזציה במודלי גרפיקה כמו CLIP?",
    "options": [
      "לשפר את מהירות יצירת התמונות באופן כללי.",
      "ללמד את המודל להכיר קונספטים חדשים ואישיים, כמו חפץ או אדם ספציפי.",
      "להקטין את גודל המודל כדי שירוץ על מכשירים חלשים יותר.",
      "לתרגם טקסט לשפות שונות באופן אוטומטי."
    ],
    "correctAnswerIndex": 1,
    "explanation": "פרסונליזציה היא תת-תחום בגרפיקה שמטרתו להתאים מודל גדול כך שיכיר עולם תוכן אישי, למשל, איך נראה הכלב הספציפי של המשתמש."
  },
  {
    "type": "mc",
    "question": "בשיטת Textual Inversion, מה בעצם מאומן?",
    "options": [
      "כל המשקולות של מודל הדיפוזיה (U-Net).",
      "וקטור הטמעה (embedding) חדש המייצג את הקונספט, בעוד המודל עצמו נשאר קפוא.",
      "ה-Text Encoder בלבד.",
      "מנגנון ה-Cross Attention בלבד."
    ],
    "correctAnswerIndex": 1,
    "explanation": "ב-Textual Inversion, המודל הגדול נשאר ללא שינוי (frozen), ומבצעים אופטימיזציה רק על וקטור הטמעה חדש שמוכנס לקלט הטקסטואלי כדי לייצג את הקונספט החדש."
  },
  {
    "type": "mc",
    "question": "מהו החיסרון העיקרי של שיטת DreamBooth בהשוואה ל-Textual Inversion?",
    "options": [
      "היא דורשת יותר תמונות דוגמה.",
      "היא אינה יכולה ללמוד אובייקטים מורכבים.",
      "היא מבצעת fine-tuning על כל המודל, מה שדורש יותר משאבים ועלול לגרום לשכחת ידע קודם (catastrophic forgetting).",
      "איכות התמונות שהיא מייצרת נמוכה יותר באופן משמעותי."
    ],
    "correctAnswerIndex": 2,
    "explanation": "DreamBooth מאמנת את כל רשת ה-U-Net, מה שהופך את המודל לכבד מאוד (2-5GB) וחושף אותו לסכנת שכחת קונספטים כלליים שלמד בעבר. כדי למנוע זאת, מוסיפים לוס רגולריזציה."
  },
  {
    "type": "mc",
    "question": "איך שיטת Perfusion מנסה לשלב בין היתרונות של Inversion ו-Fine Tuning?",
    "options": [
      "היא מאמנת רק את שכבת ה-Cross Attention.",
      "היא מקפיאה את המודל ומשתמשת ביותר טוקנים חדשים.",
      "היא מבצעת עדכון משקולות ממוקד ומינימלי (rank-1 update) רק עבור הקונספט החדש, כדי למנוע השפעה על שאר הידע במודל.",
      "היא משתמשת בשני מודלים נפרדים וממזגת את התוצאות שלהם."
    ],
    "correctAnswerIndex": 2,
    "explanation": "Perfusion שואפת לעדכן את משקולות המודל באופן מינימלי ומקומי. הפתרון המתמטי לכך הוא עדכון בדרגה 1 (rank-1) שמשנה את התנהגות הרשת רק עבור הקלט הספציפי של הקונספט החדש, ושומר על התנהגותה עבור קלטים אחרים."
  },
  {
    "type": "mc",
    "question": "במשימת 'Break a Scene', כיצד המודל לומד לעשות פרסונליזציה לכמה אובייקטים מאותה תמונה?",
    "options": [
      "על ידי חיתוך התמונה למספר תמונות קטנות יותר.",
      "על ידי שימוש במודל סגמנטציה כדי ליצור מסיכות (masks) לכל אובייקט, וחישוב ה-loss רק על האזורים הרלוונטיים.",
      "על ידי תיאור טקסטואלי מפורט של כל אובייקט בנפרד.",
      "על ידי אימון מודל נפרד לכל אובייקט בתמונה."
    ],
    "correctAnswerIndex": 1,
    "explanation": "השיטה משתמשת במודל סגמנטציה כדי להפריד בין האובייקטים בתמונה. בזמן האימון, ה-loss מחושב רק על הפיקסלים השייכים לאובייקט הספציפי שלומדים, בהתבסס על המסיכה שלו."
  },
  {
    "type": "mc",
    "question": "מה הייתה הבעיה שנוצרה ב-'Break a Scene' וכיצד היא נפתרה?",
    "options": [
      "המודל לא הצליח להפריד בין אובייקטים דומים; הפתרון היה להגדיל את מספר התמונות.",
      "המודל התחיל לייצר מספר אובייקטים יחד גם כשביקשו רק אחד; הפתרון היה להוסיף Cross-Attention Loss כדי למקד את האטנשן.",
      "איכות התמונות הייתה נמוכה; הפתרון היה להשתמש במודל דיפוזיה גדול יותר.",
      "זמן האימון היה ארוך מדי; הפתרון היה להקטין את הרזולוציה."
    ],
    "correctAnswerIndex": 1,
    "explanation": "התגלה שלפעמים המודל פיתח תלות בין האובייקטים ולמד לייצר אותם יחד. הפתרון היה להוסיף פונקציית הפסד (loss) על מפות האטנשן, כדי לכפות על המודל למקד את תשומת הלב רק באזור של האובייקט הרלוונטי בכל פעם."
  },
  {
    "type": "mc",
    "question": "מהי המוטיבציה העיקרית לפיתוח 'Personalization Encoders' כמו e4t?",
    "options": [
      "לשפר את יכולת עריכת התמונות.",
      "שיטות קודמות כמו Textual Inversion הן איטיות ודורשות אופטימיזציה לכל קונספט חדש; אנקודר מאפשר להפיק את הטוקן במעבר קדימה (forward pass) אחד.",
      "להתאים את המודלים לעבודה עם וידאו.",
      "לאפשר יצירת תמונות ברזולוציה גבוהה יותר."
    ],
    "correctAnswerIndex": 1,
    "explanation": "הבעיה המרכזית בשיטות מבוססות אופטימיזציה היא שהן איטיות ודורשות משאבי חישוב רבים לכל קונספט. אנקודר לומד למפות ישירות מהתמונה אל וקטור ההטמעה (הטוקן) המתאים, מה שהופך את התהליך למהיר ויעיל בזמן ההסקה (inference)."
  },
  {
    "type": "mc",
    "question": "בארכיטקטורת IP-Adapter, מדוע מנגנון ה-Cross-Attention מופרד (decoupled)?",
    "options": [
      "כדי להקטין את השימוש בזיכרון.",
      "כדי להוסיף מנגנון אטנשן נוסף עבור התניה על תמונה, בנפרד ממנגנון האטנשן של הטקסט, ולהימנע מאובר-פיטינג.",
      "כדי לאפשר שימוש בטקסט ובתמונה בו-זמנית.",
      "זוהי פשוט בחירה עיצובית ללא סיבה פונקציונלית."
    ],
    "correctAnswerIndex": 1,
    "explanation": "במקום להעמיס על מנגנון ה-cross-attention הקיים שמשמש להתניה על טקסט, IP-Adapter מוסיף מנגנון נפרד שבו הפיצ'רים של התמונה משמשים כ-keys ו-values. זה מאפשר שליטה טובה יותר ומונע התאמת יתר (overfitting) למאפייני התמונה על חשבון הטקסט."
  },
  {
    "type": "mc",
    "question": "מהו הרעיון המרכזי מאחורי Nested Attention?",
    "options": [
      "כל שאילתה (query) מהתמונה המיוצרת מקבלת את אותו וקטור ערך (value) מהטוקן של הקונספט.",
      "כל שאילתה (query) מקבלת וקטור ערך (value) ייחודי, המאפשר להתאים פיקסלים ספציפיים (למשל, העין בדמות) לפיקסלים המקבילים בתמונת הקלט.",
      "זהו מנגנון אטנשן שפועל רק על הטקסט.",
      "זהו סוג של אטנשן שמשמש לדחיסת מידע."
    ],
    "correctAnswerIndex": 1,
    "explanation": "בניגוד לאטנשן רגיל שבו כל הפיקסלים בתמונה המיוצרת \"רואים\" את אותו ייצוג של הקונספט, Nested Attention יוצר ייצוג דינמי. כל פיקסל (query) מקבל וקטור ערך (value) שונה, מה שמאפשר העברת פרטים עשירה ומדויקת יותר מתמונת הקלט."
  },
  {
    "type": "mc",
    "question": "מהי מטרת העל של Consistent Generation (יצירה עקבית)?",
    "options": [
      "לייצר תמונה אחת באיכות הגבוהה ביותר.",
      "לייצר סט של תמונות על פי סט של פרומפטים, כך שהאובייקטים החוזרים על עצמם יהיו זהים ועקביים בכל התמונות.",
      "לערוך תמונה קיימת באופן עקבי.",
      "לייצר דמויות שתמיד נמצאות באותה תנוחה."
    ],
    "correctAnswerIndex": 1,
    "explanation": "המטרה היא לא פרסונליזציה של אובייקט בודד, אלא יצירת סדרת תמונות (למשל, סיפור קומיקס) שבהן הדמויות או האובייקטים המרכזיים שומרים על מראה עקבי וזהה לאורך כל הסדרה, גם בסצנות ובהקשרים שונים."
  },
  {
    "type": "mc",
    "question": "כיצד מנגנון Shared Self-Attention תורם ל-Consistent Generation?",
    "options": [
      "הוא גורם לכל תמונה להיווצר בנפרד לחלוטין.",
      "הוא מאפשר לתמונות שנוצרות במקביל \"לראות\" אחת את השנייה ולשתף ביניהן מידע (keys ו-values), מה שמבטיח שהאובייקטים המשותפים ייראו זהים.",
      "הוא משתף מידע רק בין הפיקסלים של אותה תמונה.",
      "הוא מגביל את המודל ליצירת אובייקט אחד בלבד."
    ],
    "correctAnswerIndex": 1,
    "explanation": "במנגנון זה, כל תמונה בתהליך היצירה יכולה לגשת לפיצ'רים (keys ו-values) של התמונות האחרות שנוצרות יחד איתה. שיתוף מידע זה מכריח את המודל לייצר ייצוגים עקביים לאובייקטים המשותפים בין התמונות."
  },
  {
    "type": "mc",
    "question": "ב-Consistent Generation, מדוע משתמשים ב-Masked Shared Attention?",
    "options": [
      "כדי להאיץ את תהליך היצירה.",
      "כדי למנוע שיתוף יתר של מידע (למשל, רקע זהה בכל התמונות) ולאפשר שיתוף מידע רק באזורים בהם האובייקט המשותף מופיע.",
      "כדי להוסיף יותר פרטים לאובייקטים.",
      "זו טכניקה שנועדה להקטין את צריכת הזיכרון."
    ],
    "correctAnswerIndex": 1,
    "explanation": "שיתוף מלא (unmasked) עלול לגרום לכך שכל התמונות ייראו דומות מדי, כולל הרקע והקומפוזיציה. המיסוך, המבוסס על מפות cross-attention, מגביל את שיתוף המידע רק לאזורים הרלוונטיים של האובייקט העקבי, ומאפשר גיוון ברקעים ובסצנות."
  },
  {
    "type": "mc",
    "question": "מהי טכניקת 'Anchoring' בהקשר של יצירה עקבית?",
    "options": [
      "יצירת תמונות ללא אובייקטים כלל.",
      "שימוש בתמונה אחת בלבד כרפרנס.",
      "יצירת סט תמונות ראשוני שמשמש כ\"עוגן\", ולאחר מכן יצירת תמונות נוספות שמתייחסות לסט העוגנים הזה כדי לשמור על עקביות.",
      "נעילת המשקולות של המודל לאחר יצירת התמונה הראשונה."
    ],
    "correctAnswerIndex": 2,
    "explanation": "במקום לייצר את כל התמונות יחד, ניתן לייצר קבוצה קטנה של תמונות \"עוגן\" שנוצרות עם שיתוף מידע מלא ביניהן. לאחר מכן, ניתן לייצר תמונות חדשות באופן סדרתי, כאשר כל תמונה חדשה מתייחסת לעוגנים (אך לא לתמונות החדשות האחרות) כדי לשמור על עקביות."
  },
  {
    "type": "mc",
    "question": "מהו היתרון המרכזי של שיטות Consistent Generation כמו זו שהוצגה בהרצאה?",
    "options": [
      "הן מהירות יותר מכל שיטת פרסונליזציה אחרת.",
      "הן דורשות אימון מחדש של המודל עבור כל סט תמונות.",
      "הן אינן דורשות כלל אימון או fine-tuning; כל התהליך מתרחש בזמן ההסקה (inference).",
      "הן עובדות רק עבור דמויות מצוירות."
    ],
    "correctAnswerIndex": 2,
    "explanation": "היתרון הגדול של השיטה שהוצגה הוא שהיא פועלת בזמן ההסקה בלבד (training-free). אין צורך בתהליך אופטימיזציה או אימון מחדש של המודל, מה שהופך אותה לגמישה ומהירה לשימוש עבור כל סט חדש של פרומפטים."
  },
  {
    "type": "mc",
    "question": "איך משיגים גיוון בתנוחות (Pose Variation) ב-Consistent Generation?",
    "options": [
      "על ידי שינוי מפורש של הפרומפט.",
      "על ידי שימוש ב-Mask Dropout, כלומר כיבוי אקראי של חלק מה-key/values המשותפים, ושימוש בפיצ'רים מבניים מיצירה רגילה.",
      "על ידי שימוש במודל נפרד ליצירת תנוחות.",
      "המודל עושה זאת אוטומטית ללא התערבות."
    ],
    "correctAnswerIndex": 1,
    "explanation": "כדי למנוע מהדמות להופיע באותה תנוחה, משתמשים בשתי טכניקות: Mask Dropout שמכניס אקראיות לשיתוף המידע, ושילוב פיצ'רים מבניים (למשל, מפת עומק או קווי מתאר) מיצירה רגילה של Stable Diffusion, מה שמנחה את הקומפוזיציה הכללית."
  },
  {
    "type": "mc",
    "question": "בשלב הראשון של אימון האנקודר לפרסונליזציה (לפני שלב ה-optimization), על אילו תמונות מאמנים את הרשת?",
    "options": [
      "רק על תמונות של האובייקט הספציפי (למשל, הכלב שלי).",
      "על תמונות כלליות מהמחלקה של האובייקט (למשל, תמונות של כלבים באופן כללי).",
      "על תמונות אקראיות מכל נושא אפשרי.",
      "לא מאמנים את הרשת כלל בשלב זה."
    ],
    "correctAnswerIndex": 1,
    "explanation": "השלב הראשון נועד להביא את הייצוג לאזור הכללי הנכון במרחב הלטנטי. לכן, משתמשים בתמונות רבות של המחלקה הכללית (כמו 'כלב') כדי לאמן אנקודר שממפה תמונות לייצוג טקסטואלי קרוב."
  },
  {
    "type": "mc",
    "question": "מהי הבעיה בשימוש באנקודר e4t שהוזכרה בהרצאה?",
    "options": [
      "הוא איטי מאוד.",
      "הוא לא יכול ללמוד פרטים עדינים.",
      "הוא אינו יכול להכליל למספר דומיינים בו-זמנית, ועובד טוב רק על דומיין ספציפי (כמו פנים) שעליו אומן.",
      "גודל הטוקן שהוא מייצר גדול מדי."
    ],
    "correctAnswerIndex": 2,
    "explanation": "החיסרון המרכזי שצוין הוא שהאנקודר ספציפי לדומיין. אנקודר שאומן על פנים יתקשה לבצע פרסונליזציה לאובייקטים כמו מכוניות או חיות, ולהיפך. הוא חסר יכולת הכללה טובה בין דומיינים שונים."
  },
  {
    "type": "mc",
    "question": "איזו שיטה מבצעת fine-tuning על כל מודל ה-U-Net?",
    "options": ["Textual Inversion", "DreamBooth", "IP-Adapter", "Perfusion"],
    "correctAnswerIndex": 1,
    "explanation": "DreamBooth היא שיטת fine-tuning שבה מאמנים את כל רשת ה-U-Net כדי להתאים אותה לקונספט החדש, בניגוד לשיטות inversion שמקפיאות את הרשת."
  },
  {
    "type": "mc",
    "question": "בארכיטקטורת OmniControl, מהו הרעיון של 'Shared Self-Attention'?",
    "options": [
      "שימוש באטנשן רק על תמונת הקלט.",
      "הוצאת keys ו-values גם מהתמונה שמתנים עליה (C) וגם מהתמונה שנוצרת (X), ושיתופם בתהליך האטנשן.",
      "שימוש במנגנון אטנשן קטן יותר כדי לחסוך בחישובים.",
      "ביצוע אטנשן בין טקסט לטקסט."
    ],
    "correctAnswerIndex": 1,
    "explanation": "במנגנון זה, גם תמונת הקלט (C) וגם התמונה הנוכחית בתהליך הדיפוזיה (X) תורמות K (keys) ו-V (values). ה-Q (queries) מגיעים מ-X, וכך המודל יכול לשים לב לקשרים בין התמונה הנוצרת לתמונת הרפרנס."
  },
  {
    "type": "mc",
    "question": "איזו מהשיטות הבאות מסווגת כשיטת 'Inversion'?",
    "options": [
      "DreamBooth",
      "Standard Fine Tuning",
      "Textual Inversion",
      "\"Vanilla\" LORA"
    ],
    "correctAnswerIndex": 2,
    "explanation": "שיטות Inversion מאופיינות בכך שהן מקפיאות את המודל ולומדות ייצוג חדש (טוקן) במרחבים הקיימים. Textual Inversion היא הדוגמה הקלאסית לכך."
  },
  {
    "type": "open",
    "question": "הסבר במילים שלך את ההבדל המהותי בין שיטת Textual Inversion לשיטת DreamBooth.",
    "correctAnswerText": "ב-Textual Inversion, המודל הגנרטיבי כולו נשאר קפוא (ללא שינוי), ומבצעים אופטימיזציה רק כדי למצוא וקטור הטמעה (embedding) חדש בתוך מרחב הטקסט שייצג את הקונספט. לעומת זאת, ב-DreamBooth, מבצעים fine-tuning על כל המשקולות של מודל ה-U-Net עצמו כדי להטמיע את הקונספט החדש ישירות בתוך הרשת.",
    "explanation": "ההבדל המרכזי הוא מה מאמנים: Textual Inversion מאמנת רק טוקן קטן (כ-3KB) ומשאירה את המודל הגדול ללא שינוי, בעוד DreamBooth מאמנת את כל המודל (או חלק גדול ממנו), מה שיוצר קובץ גדול (2-5GB) ודורש יותר משאבים."
  },
  {
    "type": "open",
    "question": "מדוע יש צורך בשני שלבי אופטימיזציה בלימוד אנקודר לפרסונליזציה, כפי שהוצג בתחילת ההרצאה?",
    "correctAnswerText": "השלב הראשון משתמש בתמונות כלליות (למשל, 'כלב') כדי להביא את הייצוג של הקונספט לאזור הכללי הנכון במרחב הלטנטי. זה הכרחי כי לרוב אין מספיק תמונות של הקונספט הספציפי (למשל, 'הכלב שלי'). השלב השני הוא שלב fine-tuning שמשתמש בתמונות הספציפיות כדי לדייק את הייצוג ולהבדיל אותו מהקונספט הכללי.",
    "explanation": "השלב הראשון פותר את בעיית נדירות המידע (data scarcity) על ידי למידת ייצוג התחלתי טוב, והשלב השני מתמקד בפרטים הייחודיים של האובייקט הספציפי."
  },
  {
    "type": "open",
    "question": "מהי הבעיה ש-IP-Adapter מנסה לפתור, וכיצד הוא עושה זאת?",
    "correctAnswerText": "IP-Adapter מנסה לאפשר התניה חזקה על תמונה (image conditioning) מבלי לאבד את יכולת ההתאמה לטקסט (text alignment). הוא פותר זאת על ידי הוספת מנגנון cross-attention נפרד עבור הפיצ'רים של התמונה, במקום להעמיס אותם על מנגנון האטנשן הקיים של הטקסט. זה מונע התאמת יתר לתמונה ושומר על גמישות.",
    "explanation": "הפרדת מנגנוני האטנשן (decoupled cross-attention) מאפשרת למודל לשלב מידע מהטקסט ומהתמונה בצורה מאוזנת יותר, מה שמוביל לתוצאות טובות יותר שבהן גם זהות האובייקט וגם הפרומפט הטקסטואלי נשמרים."
  },
  {
    "type": "open",
    "question": "מהו הרעיון הבסיסי מאחורי שיטת Perfusion?",
    "correctAnswerText": "Perfusion מנסה למצוא את דרך האמצע בין שיטות Inversion (שלא משנות את המודל כלל) לבין שיטות Fine-Tuning (שמשנות את כל המודל). היא עושה זאת על ידי ביצוע עדכון משקולות ממוקד מאוד ומינימלי ברשת, כך שהשינוי ישפיע רק על הקונספט החדש ולא יפגע בידע הכללי שהמודל כבר רכש.",
    "explanation": "הרעיון הוא לעשות שינוי 'כירורגי' במשקולות. הפתרון הפורמלי הוא עדכון בדרגה נמוכה (rank-1) שמשנה את פלט הרשת רק עבור קלט ספציפי (הטוקן של הקונספט) תוך שמירה על הפלט עבור כל שאר הקלטים."
  },
  {
    "type": "open",
    "question": "הסבר כיצד פועל מנגנון ה-Shared Self-Attention ב-Consistent Generation.",
    "correctAnswerText": "כאשר מייצרים מספר תמונות במקביל, מנגנון האטנשן מאפשר לכל תמונה בתהליך היצירה לגשת לפיצ'רים (ל-keys ול-values) של כל התמונות האחרות. כך נוצר שיתוף מידע בין התמונות, והמודל 'נאלץ' לייצר ייצוגים ויזואליים זהים לאובייקטים שמופיעים בפרומפטים של כל התמונות.",
    "explanation": "במקום שכל תמונה 'תסתכל' רק על הפיקסלים של עצמה (כמו ב-self-attention רגיל), היא מסתכלת גם על הפיקסלים של התמונות האחרות שנוצרות יחד איתה, מה שמאפשר אכיפה של עקביות."
  },
  {
    "type": "open",
    "question": "מה ההבדל בין משימת הפרסונליזציה (Personalization) לבין משימת היצירה העקבית (Consistent Generation)?",
    "correctAnswerText": "בפרסונליזציה, המטרה היא ללמד מודל זהות של אובייקט ספציפי מקבוצה קטנה של תמונות, כדי שניתן יהיה לייצר אותו מאוחר יותר בהקשרים שונים. ביצירה עקבית, המטרה היא לייצר קבוצה של תמונות על פי קבוצה של פרומפטים, ולהבטיח שהזהות של אובייקטים החוזרים על עצמם תישמר באופן עקבי לאורך כל קבוצת התמונות.",
    "explanation": "פרסונליזציה עוסקת בלימוד זהות (שלב אימון/אופטימיזציה), בעוד יצירה עקבית עוסקת ביישום זהות על פני מספר יצירות בו-זמנית (שלב הסקה)."
  },
  {
    "type": "open",
    "question": "מהי המגבלה של שיטות פרסונליזציה מבוססות אופטימיזציה (כמו Textual Inversion) שאנקודרים (כמו e4t) מנסים לפתור?",
    "correctAnswerText": "הבעיה העיקרית היא שהן איטיות ודורשות תהליך אופטימיזציה איטרטיבי נפרד עבור כל קונספט חדש שרוצים ללמד. אנקודר, לעומת זאת, לאחר שאומן, יכול להפיק את הייצוג (הטוקן) של קונספט חדש במעבר קדימה (forward pass) בודד, מה שהופך את התהליך למהיר ויעיל הרבה יותר.",
    "explanation": "המעבר מאופטימיזציה לאנקודר הוא מעבר מתהליך 'חיפוש' איטי לתהליך 'חישוב' מהיר, מה שמשפר משמעותית את השימושיות של פרסונליזציה בזמן אמת."
  },
  {
    "type": "open",
    "question": "תאר את הרעיון מאחורי מנגנון Nested Attention.",
    "correctAnswerText": "במנגנון אטנשן רגיל, כל הפיקסלים בתמונה המיוצרת (queries) מקבלים את אותו וקטור ערך (value) עבור טוקן מסוים (למשל, הטוקן של האדם). ב-Nested Attention, כל פיקסל מקבל וקטור ערך ייחודי, המאפשר להתאים את המידע מהטוקן באופן ספציפי לאותו פיקסל. למשל, פיקסלים באזור העין יקבלו מידע שרלוונטי יותר לעין מתמונת המקור.",
    "explanation": "זהו מנגנון שמאפשר העברת פרטים עשירה ומדויקת יותר מתמונת הקלט, מכיוון שהוא יוצר ייצוג דינמי של הקונספט שתלוי במיקום המרחבי בתמונה המיוצרת."
  },
  {
    "type": "open",
    "question": "מדוע בשיטת DreamBooth יש צורך להוסיף loss שגורם למודל לזכור איך לייצר אובייקטים כלליים (למשל, כלבים באופן כללי)?",
    "correctAnswerText": "מכיוון ש-DreamBooth מבצעת fine-tuning על כל משקולות המודל, היא נמצאת בסיכון גבוה ל'שכחה קטסטרופלית' (catastrophic forgetting). כלומר, בזמן שהיא מתמחה ביצירת האובייקט הספציפי (למשל, 'הכלב שלי'), היא עלולה לשכוח איך לייצר אובייקטים אחרים מאותה קטגוריה (כלבים אחרים). ה-loss הנוסף משמש כרגולריזציה ששומרת על הידע הכללי של המודל.",
    "explanation": "ה-loss הזה מאזן בין למידת הקונספט הספציפי לבין שימור הידע הכללי, ומונע התאמת יתר (overfitting) לקונספט החדש."
  },
  {
    "type": "open",
    "question": "בהינתן תמונה עם מספר אובייקטים, כיצד שיטת 'Break a Scene' משתמשת במסיכות (masks) כדי למנוע בלבול בין האובייקטים בזמן אימון הפרסונליזציה?",
    "correctAnswerText": "לאחר שימוש במודל סגמנטציה כדי לקבל מסיכה לכל אובייקט, בזמן אימון הפרסונליזציה עבור אובייקט ספציפי (למשל, [V1]), פונקציית ההפסד (loss) של הדיפוזיה מחושבת רק על הפיקסלים שמתאימים למסיכה של אותו אובייקט. בנוסף, מוסיפים cross-attention loss כדי לאכוף על המודל למקד את האטנשן שלו רק באזור הממוסך של האובייקט הרלוונטי.",
    "explanation": "השימוש הכפול במסיכות - גם לחישוב ה-loss וגם להנחיית מנגנון האטנשן - מבטיח שהמודל לומד לקשר כל טוקן חדש ([V1], [V2]) באופן בלעדי לפיקסלים ולמאפיינים של האובייקט המתאים לו, ומונע ממנו 'לערבב' ביניהם."
  }
]
