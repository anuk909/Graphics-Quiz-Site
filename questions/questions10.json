[
  {
    "type": "mc",
    "question": "מהי המטרה העיקרית של מודל ControlNet?",
    "options": [
      "להחליף לחלוטין את Stable Diffusion במודל יעיל יותר.",
      "להוסיף יכולת שליטה על מבנה התמונה הסופית באמצעות תמונת קלט נוספת.",
      "לשפר את מהירות יצירת התמונה על חשבון איכות.",
      "להתמקד ביצירת תמונות מתוך טקסט בלבד, ללא קלט חזותי."
    ],
    "correctAnswerIndex": 1,
    "explanation": "ControlNet מרחיב את Stable Diffusion על ידי הוספת ענף מקביל שניתן לאימון. ענף זה מקבל תמונת קלט (כגון שרטוט קווי, מפת עומק וכו') ומשתמש בה כדי להנחות את מבנה התמונה שהמודל הראשי מייצר, ובכך מאפשר שליטה מדויקת יותר על התוצאה."
  },
  {
    "type": "mc",
    "question": "מה הבעיה ששיטת 'Attend-and-Excite' באה לפתור?",
    "options": [
      "זמן ריצה ארוך של מודלי דיפוזיה.",
      "רזולוציה נמוכה של התמונות המיוצרות.",
      "נטייה של מודלים להתעלם מאובייקטים מסוימים בפרומפט או למזג תכונות בין אובייקטים דומים.",
      "קושי ביצירת טקסטורות מורכבות כמו פרווה או מים."
    ],
    "correctAnswerIndex": 2,
    "explanation": "Attend-and-Excite מטפל בבעיית ה-'attention leakage', שבה אובייקטים דומים סמנטית (כמו 'חתול' ו'כלב') חולקים תכונות, או במקרים שבהם אובייקט מהפרומפט כלל לא מופיע בתמונה. השיטה מחזקת ומחדדת את מפות ה-attention עבור כל אובייקט."
  },
  {
    "type": "mc",
    "question": "במנגנון Cross Image Attention להעברת מראה (Appearance Transfer), מהיכן נלקחים ה-Query (Q) ומהיכן ה-Key (K) וה-Value (V)?",
    "options": [
      "Q, K, V כולם מתמונת המבנה (Structure).",
      "Q מתמונת המראה (Appearance), ו-K, V מתמונת המבנה.",
      "Q מתמונת המבנה, ו-K, V מתמונת המראה.",
      "Q, K, V כולם מתמונת המראה (Appearance)."
    ],
    "correctAnswerIndex": 2,
    "explanation": "כדי להעביר את המראה של תמונה אחת על המבנה של אחרת, ה-Query נלקח מתמונת המבנה (לדוגמה, ג'ירפה) והוא 'שואל' איזה חלק בתמונת המראה (לדוגמה, זברה) הכי מתאים לו. ה-Key וה-Value, שמכילים את המידע על המראה, נלקחים מתמונת המראה."
  },
  {
    "type": "mc",
    "question": "כיצד מתבצעת סגמנטציה של התמונה באופן 'zero-shot' (ללא אימון ייעודי) במודלי דיפוזיה?",
    "options": [
      "על ידי שימוש במודל חיצוני שמיועד לסגמנטציה בלבד.",
      "על ידי הוספת שכבת סגמנטציה ייעודית ואימון קצר שלה.",
      "על ידי ביצוע אשכול (clustering) על מפות ה-self-attention של המודל.",
      "על ידי בקשה מפורשת בפרומפט הטקסטואלי לבצע סגמנטציה."
    ],
    "correctAnswerIndex": 2,
    "explanation": "מפות ה-self-attention במודל לומדות קשרים סמנטיים בין אזורים שונים בתמונה. ניתן לנצל מידע זה ועל ידי קיבוץ (אשכול) של וקטורי ה-attention, לזהות אילו פיקסלים שייכים לאותו אובייקט, וכך לקבל סגמנטציה ללא כל אימון נוסף."
  },
  {
    "type": "mc",
    "question": "מהי תופעת 'Attention Leakage' (זליגת קשב) בהקשר של יצירת תמונות?",
    "options": [
      "כאשר המודל מקדיש יותר מדי קשב לרקע במקום לאובייקט המרכזי.",
      "כאשר תכונות של אובייקט אחד 'זולגות' ומשפיעות על המראה של אובייקט אחר בתמונה, במיוחד כשהם דומים סמנטית.",
      "כאשר מפות ה-attention חלשות מדי ולא מצליחות להתמקד בשום אזור ספציפי.",
      "דליפת זיכרון במחשב הנגרמת מחישובי attention כבדים."
    ],
    "correctAnswerIndex": 1,
    "explanation": "התופעה מתרחשת כאשר מנסים לייצר שני אובייקטים דומים סמנטית (למשל 'חתול וכלבלב'). בגלל הקרבה הסמנטית שלהם במרחב ה-embedding, מפות ה-attention שלהם דומות, מה שגורם להם 'לחלוק' ערכי Value ולקבל תכונות מעורבבות."
  },
  {
    "type": "mc",
    "question": "בשיטת Bounded Attention, מה המטרה העיקרית של חסימת ה-self-attention בין אזורי התיבות התוחמות (bounding boxes)?",
    "options": [
      "לשפר את צבעי האובייקטים.",
      "להאיץ את תהליך ה-denoising.",
      "להכריח את המודל להתעלם מהרקע.",
      "למנוע מהאובייקטים לחלוק מידע ולערבב את התכונות שלהם."
    ],
    "correctAnswerIndex": 3,
    "explanation": "בנוסף להנחיית ה-cross-attention, בשיטה זו חוסמים גם את ה-self-attention בין האזורים שהוגדרו למשל עבור החתול והכלב. זה מונע מהפיקסלים באזור של החתול להסתכל על הפיקסלים באזור של הכלב (ולהפך), ובכך מונע ביעילות את זליגת התכונות ביניהם."
  },
  {
    "type": "mc",
    "question": "מהו הטריק 'zero conv' שמוזכר בהקשר של ControlNet?",
    "options": [
      "שכבת קונבולוציה שמכפילה הכל באפס כדי למחוק מידע לא רצוי.",
      "שכבת קונבולוציה שהמשקלים וה-bias שלה מאותחלים לאפס.",
      "טכניקה לביצוע קונבולוציה ללא פעולות כפל.",
      "שימוש בקונבולוציה כדי ליצור רעש התחלתי."
    ],
    "correctAnswerIndex": 1,
    "explanation": "זוהי שכבת קונבולוציה (1x1) שהמשקלים וה-bias שלה מאותחלים לאפס. היא ממוקמת בחיבור בין הענף המאומן של ControlNet למודל ה-SD הקפוא. האתחול לאפס גורם לכך שבתחילת האימון, ה-ControlNet לא משפיע כלל על מודל ה-SD, ושומר על היכולות המקוריות שלו. הוא 'לומד' להוסיף מידע רק אם זה נדרש."
  },
  {
    "type": "mc",
    "question": "מה הייתה הבעיה בשימוש ב-Cross Image Attention על דומיינים מסוימים, כמו בניינים?",
    "options": [
      "השיטה עבדה לאט מדי עבור תמונות של בניינים.",
      "נוצרו הרבה ארטיפקטים והתוצאה הייתה רועשת.",
      "הצבעים של הבניינים תמיד יצאו דהויים.",
      "היה קשה למצוא זוגות תמונות של בניינים לאימון."
    ],
    "correctAnswerIndex": 1,
    "explanation": "נמצא כי עבור דומיינים מסוימים כמו בניינים, מפות ה-attention היו רועשות, מה שהוביל להרבה ארטיפקטים ויזואליים בתוצאת העברת המראה."
  },
  {
    "type": "mc",
    "question": "בשיטת 'Style Aligned', כיצד מבטיחים שכל התמונות המיוצרות חולקות את אותו סגנון?",
    "options": [
      "על ידי שימוש באותו פרומפט מדויק עבור כל התמונות.",
      "על ידי יצירת תמונת רפרנס אחת, ושכל שאר התמונות ייקחו ממנה את מפות ה-Key וה-Value.",
      "על ידי הרצת פילטר סגנון על כל התמונות לאחר שהן נוצרו.",
      "על ידי אימון מודל נפרד לכל סגנון רצוי."
    ],
    "correctAnswerIndex": 1,
    "explanation": "הרעיון הוא להרחיב את מנגנון ה-cross-attention. מייצרים תמונת רפרנס אחת, ובכל שלב של יצירת שאר התמונות, הן משתמשות במפות ה-Key וה-Value של תמונת הרפרנס. כך, הן מתיישרות לפי הסגנון שלה."
  },
  {
    "type": "mc",
    "question": "מדוע שיטת Layout Guidance לפעמים דוחפת את המודל לאזורים 'out of distribution'?",
    "options": [
      "כי היא משתמשת ביותר מדי זיכרון RAM.",
      "כי היא מכריחה אזור בתמונה להיות קרוב סמנטית לאובייקט אחד (למשל, כלב) ובמקביל רחוק מאובייקט אחר (למשל, חתול), למרות שהם דומים.",
      "כי היא משנה את הפרומפט המקורי באופן אוטומטי.",
      "כי התיבות התוחמות שהמשתמש מצייר קטנות מדי."
    ],
    "correctAnswerIndex": 1,
    "explanation": "הבעיה נוצרת מהדרישה הכפולה ב-loss: לחזק את הקשר בין אזור ל'כלב' ולהחליש את הקשר ל'חתול'. מכיוון שכלב וחתול הם מושגים קרובים סמנטית, הדרישה להרחיק אותם באופן אקטיבי עלולה לדחוף את המודל למצב שהוא לא מכיר מהאימון שלו."
  },
  {
    "type": "mc",
    "question": "מהי אחת הפעולות שניתן לעשות כדי לשפר את תוצאות Cross-Image Attention בדומיינים בעייתיים?",
    "options": [
      "להנמיך את הרזולוציה של תמונת המראה (appearance).",
      "להגביר את הקונטרסט של תמונת המראה.",
      "להמיר את התמונות לגווני אפור.",
      "להוסיף רעש גאוסיאני לתמונת המבנה."
    ],
    "correctAnswerIndex": 1,
    "explanation": "אחת מהטכניקות שהוצעו היא להגביר את השונות (variance) של תמונת המראה תוך שמירה על הממוצע. פעולה זו מגבירה את הקונטרסט ועוזרת ליצור מפות attention פחות רועשות."
  },
  {
    "type": "mc",
    "question": "במשימת inpainting, כיצד ניתן ליצור דאטה-סט זוגי (paired dataset) לאימון מודל דיפוזיה?",
    "options": [
      "מצלמים כל סצנה פעמיים, עם ובלי האובייקט.",
      "לוקחים תמונה רגילה, מעבירים אותה ב-VAE, ואז מוספים רעש לתמונה המשוחזרת.",
      "לוקחים תמונה רגילה, יוצרים מסיכה באופן כלשהו (למשל עם מודל סגמנטציה), ומאמנים את המודל לשחזר את התמונה המקורית מהתמונה הממוסכת.",
      "משתמשים בשתי תמונות שונות לגמרי ומצפים מהמודל למצוא את הדמיון ביניהן."
    ],
    "correctAnswerIndex": 2,
    "explanation": "הדרך הפשוטה היא להתחיל מתמונה שלמה (המטרה), ליצור עבורה מסיכה, ולהשתמש בתמונה הממוסכת כקלט. המודל לומד להשלים את האזור הממוסך כדי לשחזר את התמונה המקורית."
  },
  {
    "type": "mc",
    "question": "מה השינוי המרכזי שנעשה ב-Bounded Attention לעומת Layout Guidance בשלב ה-guidance?",
    "options": [
      "דורשים שה-attention יהיה נמוך יותר בכל האזורים.",
      "מעודדים attention גבוה לאובייקט בתוך המסגרת שלו, אך לא 'מענישים' אותו על attention באזורים אחרים.",
      "משתמשים בסוג loss שונה לחלוטין שמבוסס על צבע.",
      "מכפילים את כמות הצעדים בתהליך ה-guidance."
    ],
    "correctAnswerIndex": 1,
    "explanation": "במקום לדרוש מהמודל שבאזור החתול יהיה attention גבוה ל'חתול' ונמוך ל'כלב', השיטה החדשה רק מעודדת את ה-attention הגבוה ל'חתול' במסגרת שלו ופשוט לא מכניסה ל-loss את הדרישה לגבי המסגרת של הכלב. זה מונע את הדחיפה לאזורים 'out of distribution'."
  },
  {
    "type": "mc",
    "question": "בהקשר של Self-Segmentation, לאחר שמקבלים את מקבצי הפיקסלים, כיצד ניתן לתת להם תוויות טקסטואליות?",
    "options": [
      "המשתמש צריך לתייג כל מקבץ ידנית.",
      "מריצים מודל זיהוי אובייקטים נפרד על כל מקבץ.",
      "בודקים את הקשר בין כל מקבץ למילים בפרומפט באמצעות מפות ה-cross-attention.",
      "הצבע של כל מקבץ מייצג תווית קבועה מראש."
    ],
    "correctAnswerIndex": 2,
    "explanation": "בזכות מנגנון ה-cross-attention, ניתן לבדוק עבור כל מקבץ (segment) לאיזו מילה בפרומפט הטקסטואלי יש את ה-attention הגבוה ביותר, וכך לשייך אוטומטית תווית טקסטואלית לכל חלק בתמונה."
  },
  {
    "type": "mc",
    "question": "מה הרעיון בחישוב ה-Loss בשיטת Attend-and-Excite?",
    "options": [
      "למזער את ההבדל בין התמונה שנוצרה לתמונה אמיתית.",
      "לדאוג שערך הפיקסל המקסימלי במפת ה-attention של כל אובייקט יהיה קרוב ל-1.",
      "להשוות את ההיסטוגרמה של התמונה המיוצרת לתמונת היעד.",
      "לסכום את כל ערכי ה-attention ולוודא שהסכום גבוה."
    ],
    "correctAnswerIndex": 1,
    "explanation": "ה-loss מחושב כך שהוא שואף למקסם את הערך החזק ביותר במפת ה-attention של כל אובייקט (לאחר החלקה גאוסיאנית). מפת attention 'חדה' עם ערך מקסימלי גבוה מעידה שהמודל התמקד באזור ספציפי עבור האובייקט, ולא 'מרח' אותו."
  },
  {
    "type": "mc",
    "question": "איזו בעיה עלולה להיווצר כאשר מנסים לייצר תמונה עם 'ג'ירפה וזברה' באותה תמונה?",
    "options": [
      "המודל ייצור רק את החיה שמופיעה ראשונה בפרומפט.",
      "צבעי הרקע יהיו מבולגנים.",
      "המודל ייצור חיית כלאיים שמשלבת תכונות של ג'ירפה וזברה.",
      "התמונה תיווצר ברזולוציה נמוכה מאוד."
    ],
    "correctAnswerIndex": 2,
    "explanation": "בגלל שיש התאמה סמנטית (semantic correspondence) חזקה בין ג'ירפה לזברה (ארבע רגליים, זנב, ראש וכו'), המודל עלול לערבב את התכונות שלהן וליצור יצור היברידי במקום שתי חיות נפרדות."
  },
  {
    "type": "mc",
    "question": "מהי אחת השיטות להתאים את הסטטיסטיקה של התמונה המיוצרת לזו של תמונת המראה (appearance) בבעיות של Cross-Image Attention?",
    "options": [
      "שימוש ב-Dropout.",
      "הפעלת Batch Normalization.",
      "החלת AdaIN (Adaptive Instance Normalization).",
      "הוספת שכבת max-pooling."
    ],
    "correctAnswerIndex": 2,
    "explanation": "אחת הדרכים שהוצעו היא להשתמש ב-AdaIN כדי להתאים את הסטטיסטיקות (ממוצע וסטיית תקן) של ה-feature maps של התמונה המיוצרת לאלו של תמונת המראה. זה עוזר להתגבר על 'פער הדומיין' ביניהן."
  },
  {
    "type": "mc",
    "question": "איזו פעולה מתבצעת באופן איטרטיבי תוך כדי תהליך ה-denoising בשיטת Attend-and-Excite?",
    "options": [
      "שינוי גודל התמונה.",
      "חידוד התמונה באמצעות פילטר sharpening.",
      "לקיחת צעד גרדיאנט כדי למזער את ה-loss של מפות ה-attention.",
      "הוספת רעש נוסף לתמונה."
    ],
    "correctAnswerIndex": 2,
    "explanation": "בכל צעד של תהליך ה-denoising, מחושב ה-loss של 'מריחות' מפות ה-attention. לאחר מכן, מתבצע צעד אופטימיזציה (gradient descent) על ה-latent (z_t) כדי לעדכן אותו לכיוון שממזער את ה-loss הזה, לפני שמחשבים את ה-latent של הצעד הבא."
  },
  {
    "type": "mc",
    "question": "מדוע בשיטת Style Aligned משתמשים גם ב-AdaIN?",
    "options": [
      "כדי להאיץ את החישובים.",
      "כדי להתגבר על אותו 'פער דומיין' (domain gap) שעלול להיווצר בין תמונת הרפרנס לתמונות המטרה.",
      "כדי לאפשר שימוש בפרומפטים ארוכים יותר.",
      "זוהי דרישה של ארכיטקטורת ה-Transformer."
    ],
    "correctAnswerIndex": 1,
    "explanation": "בדומה לבעיות ב-Cross-Image Attention, גם כאן עלול להיווצר פער בין התכונות של תמונת הרפרנס לאלו של תמונת המטרה. שימוש ב-AdaIN עוזר לגשר על הפער הזה ולהבטיח העברת סגנון חלקה יותר."
  },
  {
    "type": "mc",
    "question": "איזו דוגמה ממחישה בצורה הטובה ביותר בעיה של 'Missing object' במודלי טקסט-תמונה?",
    "options": [
      "פרומפט 'חתול כתום' מייצר חתול שחור.",
      "פרומפט 'כלב וחתול' מייצר תמונה של כלב היברידי עם פסי חתול.",
      "פרומפט 'כדור אדום וקוביה כחולה' מייצר תמונה של כדור אדום בלבד.",
      "פרומפט 'בית עם גג אדום' מייצר תמונה מטושטשת."
    ],
    "correctAnswerIndex": 2,
    "explanation": "בעיית 'Missing object' (או Catastrophic Forgetting) מתרחשת כאשר המודל פשוט מתעלם מאחד האובייקטים שהוזכרו בפרומפט, במיוחד כשהפרומפט מורכב."
  },
  {
    "type": "open",
    "question": "הסבר בקצרה את התהליך של יצירת תמונה באמצעות ControlNet, תוך התייחסות למודל ה'קפוא' ולעותק ה'ניתן לאימון'.",
    "correctAnswerText": "ב-ControlNet, לוקחים מודל Stable Diffusion מאומן ו'מקפיאים' את משקולותיו. במקביל, יוצרים עותק של שכבות ה-encoder שלו, שהמשקולות שלו כן ניתנות לאימון. תמונת הקלט (למשל, שרטוט) מוזנת לעותק המאומן, והפלט שלו, המכיל את המידע המבני, מתווסף לפלט של השכבה המקבילה במודל הקפוא. סכום זה מנחה את תהליך ה-denoising.",
    "explanation": "הארכיטקטורה הזו מאפשרת להוסיף יכולת שליטה חדשה (הנחיה מתמונה) למודל SD קיים וחזק, מבלי לאבד את הידע העצום שהוא כבר רכש ומבלי צורך לאמן אותו מחדש מאפס."
  },
  {
    "type": "open",
    "question": "מהי הבעייתיות בשימוש בפרומפט טקסט בלבד כדי ליצור סט תמונות עם סגנון אחיד, וכיצד שיטת Style-Aligned פותרת זאת?",
    "correctAnswerText": "הבעיה היא שלמרות שמוסיפים את אותו תיאור סגנון (למשל 'בסגנון אוריגמי') לכל הפרומפטים, המודל עדיין מייצר וריאציות גדולות בסגנון בין התמונות השונות. שיטת Style-Aligned פותרת זאת על ידי יצירת תמונת רפרנס אחת, ושיתוף מפות ה-Key וה-Value שלה עם כל שאר התמונות בתהליך היצירה, מה שמכריח אותן להתיישר לאותו סגנון באופן עקבי.",
    "explanation": "עריכת הפרומפט היא דרך נאיבית שלא מבטיחה עקביות. שיתוף מפות ה-attention מתמונת רפרנס הוא מנגנון חזק יותר שמבטיח שהבסיס הסגנוני של כל התמונות בסט יהיה זהה."
  },
  {
    "type": "open",
    "question": "הסבר מהי 'זליגת תכונות' (attribute leakage) וציין שתי סיבות עיקריות להתרחשותה במודלי דיפוזיה.",
    "correctAnswerText": "זליגת תכונות היא תופעה שבה מאפיינים של אובייקט אחד בתמונה 'זולגים' ומשפיעים על המראה של אובייקט אחר. הסיבות העיקריות הן: 1. קרבה סמנטית: מילים כמו 'חתול' ו'כלב' קרובות במרחב ה-embedding, מה שגורם להן לקבל מפות attention דומות. 2. מנגנון ה-cross attention: בגלל מפות ה-attention הדומות, הפיצ'רים של שני האובייקטים (ה-queries) 'מושכים' את אותם ערכים (values) מהטקסט, מה שגורם לערבוב תכונות.",
    "explanation": "הבעיה מחמירה עם התקדמות תהליך ה-denoising, מכיוון שהזליגה מצטברת משלב לשלב."
  },
  {
    "type": "open",
    "question": "תאר את ההבדל המרכזי בין שיטת Layout Guidance לבין Bounded Attention בטיפול בזליגת תכונות.",
    "correctAnswerText": "ב-Layout Guidance, ה-loss מעודד attention גבוה לאובייקט הנכון וגם 'מעניש' על attention לאובייקטים אחרים, מה שעלול להיות בעייתי. ב-Bounded Attention, ה-guidance רק מעודד attention גבוה לאובייקט הנכון בתוך המסגרת שלו, ללא ענישה. בנוסף, Bounded Attention אוכף הפרדה על ידי חסימה אקטיבית של ה-attention (גם cross וגם self) כך שלא יזלוג מחוץ למסגרת שהוגדרה לו בשלב ה-denoising.",
    "explanation": "Bounded Attention היא גישה מתוחכמת יותר: היא 'משחררת' את הדרישה הבעייתית ב-loss, ובמקום זאת אוכפת את ההפרדה באופן ישיר ומפורש על ידי מיסוך (masking) של מפות ה-attention."
  },
  {
    "type": "open",
    "question": "כיצד עובד מנגנון העברת המראה (Appearance Transfer) בדוגמת הג'ירפה והזברה, ומה ניתן ללמוד ממפות ה-attention במקרה זה?",
    "correctAnswerText": "המנגנון משתמש ב-cross-attention בין שתי תמונות. תמונת המבנה (ג'ירפה) מספקת את ה-Queries, ותמונת המראה (זברה) מספקת את ה-Keys וה-Values. כל אזור בג'ירפה 'מחפש' את האזור המתאים לו ביותר בזברה ומעתיק את המראה שלו. מפות ה-attention מראות שהמודל מבין את ההתאמה הסמנטית ברמה גבוהה - למשל, הראש של הג'ירפה מתאים לראש של הזברה, והרגליים לרגליים.",
    "explanation": "העובדה שמפות ה-attention מראות התאמה סמנטית כה חזקה (ראש לראש, רגל לרגל) מדגימה את עומק ההבנה של מודלים אלו, שנלמדת ללא פיקוח ישיר על התאמות כאלו."
  },
  {
    "type": "open",
    "question": "מהו הרעיון מאחורי פונקציית ה-Loss בשיטת Attend-and-Excite, וכיצד היא עוזרת למנוע 'העלמות' של אובייקטים?",
    "correctAnswerText": "הרעיון הוא להבטיח שלכל שם עצם בפרומפט תהיה מפת attention 'חדה' ולא 'מרוחה'. ה-Loss מחושב כ-1 פחות הערך המקסימלי במפת ה-attention (לאחר החלקה). מזעור ה-loss הזה גורם למודל לחזק את ה-attention על אזור מסוים עבור כל אובייקט. כאשר לאובייקט יש אזור attention חזק, הוא לא 'נעלם' מהתמונה.",
    "explanation": "כאשר אובייקט נעלם מהתמונה, מפות ה-attention שלו בדרך כלל מרוחות ובעלות ערכים נמוכים בכל הפיקסלים. ה-loss הזה מכריח את המודל ליצור 'פוקוס' ברור עבור כל אובייקט."
  },
  {
    "type": "open",
    "question": "מדוע נדרשים טריקים נוספים כמו הגברת קונטרסט או התאמת סטטיסטיקות (AdaIN) כאשר משתמשים ב-Cross-Image Attention?",
    "correctAnswerText": "מכיוון שהשיטה הבסיסית לא תמיד עובדת היטב על כל סוגי התמונות (דומיינים). בדומיינים מסוימים, כמו בניינים, נמצא שמפות ה-attention הנוצרות הן רועשות מאוד וגורמות לארטיפקטים. הטריקים הנוספים נועדו לגשר על 'פער הדומיין' בין תמונת המבנה לתמונת המראה ולייצר מפות attention נקיות וטובות יותר.",
    "explanation": "הטריקים הם למעשה תיקונים אמפיריים שנועדו לשפר את יציבות ואמינות השיטה במקרים שבהם ההתאמה בין התמונות אינה טריוויאלית."
  },
  {
    "type": "open",
    "question": "הסבר מהו התפקיד של המסיכה (mask) במשימת image inpainting.",
    "correctAnswerText": "המסיכה היא קלט בינארי שמוזן למודל בנוסף לתמונה החלקית. היא מגדירה למודל אילו אזורים בתמונה חסרים ויש להשלים (inpainting), ואילו אזורים הם חלק מהתוכן הקיים ויש לשמר. המודל משתמש במידע זה כדי למקד את תהליך היצירה לאזורים המסומנים בלבד.",
    "explanation": "בלי המסיכה, המודל לא היה יודע איזה חלק מהתמונה הוא הקלט הקיים ואיזה חלק עליו 'לדמיין'. המסיכה מספקת את ההקשר המרחבי החיוני למשימה."
  },
  {
    "type": "open",
    "question": "מה ההבדל בין cross-attention לבין self-attention בהקשר של מודלי דיפוזיה?",
    "correctAnswerText": "Self-attention מחשב קשרים בין אלמנטים בתוך אותו קלט. בהקשר של תמונה, הוא מחשב את הקשר בין כל פיקסל לשאר הפיקסלים באותה תמונה, מה שעוזר ללמוד את מבנה האובייקטים. Cross-attention מחשב קשרים בין שני קלטים שונים. למשל, בין פיקסלים בתמונה (queries) לבין מילים בפרומפט (keys, values), כדי להתאים את התמונה לטקסט.",
    "explanation": "בקצרה: self-attention הוא על קשרים פנימיים (תמונה עם עצמה), בעוד cross-attention הוא על קשרים חיצוניים (תמונה עם טקסט, או תמונה עם תמונה אחרת)."
  },
  {
    "type": "open",
    "question": "מדוע לעיתים קרובות משתמשים במודל VAE (Variational Autoencoder) בשילוב עם מודלי דיפוזיה?",
    "correctAnswerText": "מודלי דיפוזיה עובדים במרחב הפיקסלים, שהוא בעל ממדים גבוהים מאוד. כדי להפוך את התהליך ליעיל יותר, משתמשים ב-encoder של VAE כדי לדחוס את התמונה למרחב סמוי (latent space) קטן יותר. תהליך הדיפוזיה וה-denoising מתבצע במרחב הסמוי הזה. בסוף התהליך, משתמשים ב-decoder של ה-VAE כדי להמיר את הייצוג הסמוי חזרה לתמונה במרחב הפיקסלים.",
    "explanation": "העבודה במרחב הסמוי חוסכת כוח חישוב עצום ומאפשרת למודל להתמקד בלמידת המאפיינים הסמנטיים החשובים של התמונה, במקום בפרטים זניחים ברמת הפיקסל."
  }
]
