[
  {
    "type": "mc",
    "question": "מהי מטרתו העיקרית של תהליך ה-Forward Diffusion במודלי דיפוזיה?",
    "options": [
      "לייצר תמונה חדשה מתוך רעש אקראי",
      "להוסיף באופן הדרגתי רעש גאוסיאני לתמונה קיימת עד שהיא הופכת לרעש טהור",
      "ללמוד את הפרמטרים של הרשת כדי לשפר את איכות התמונה",
      "להסיר רעש מתמונה באופן איטרטיבי"
    ],
    "correctAnswerIndex": 1,
    "explanation": "תהליך ה-Forward Diffusion הוא תהליך קבוע מראש שבו מוסיפים רעש גאוסיאני לתמונה אמיתית בשלבים רבים, עד שהיא מאבדת את המידע המקורי. המודל לומד לבצע את הפעולה ההפוכה (Reverse Denoising)."
  },
  {
    "type": "mc",
    "question": "מה הרשת במודל דיפוזיה (כמו DDPM) לומדת לחזות במהלך האימון?",
    "options": [
      "את התמונה הנקייה המקורית",
      "את הרעש המדויק שהוסף לתמונה בכל שלב",
      "את קטגוריית התמונה (לדוגמה, 'חתול' או 'כלב')",
      "את התמונה בשלב הזמן הבא בתהליך"
    ],
    "correctAnswerIndex": 1,
    "explanation": "במקום לנסות לחזות ישירות את התמונה הנקייה, המודל מאומן לחזות את הרעש שהתווסף. חיסור הרעש החזוי מהתמונה הרועשת מאפשר להתקדם צעד אחד בתהליך הניקוי."
  },
  {
    "type": "mc",
    "question": "מה היתרון המרכזי של מודלי Latent Diffusion (LDM) על פני מודלי דיפוזיה סטנדרטיים?",
    "options": [
      "הם משתמשים בארכיטקטורת טרנספורמר במקום U-Net",
      "תהליך האימון שלהם יציב יותר באופן משמעותי",
      "הם מפחיתים דרמטית את העלות החישובית על ידי עבודה במרחב לטנטי קטן יותר",
      "הם תמיד מייצרים תמונות מגוונות יותר"
    ],
    "correctAnswerIndex": 2,
    "explanation": "המוטיבציה המרכזית מאחורי LDM היא יעילות. במקום לבצע את תהליך הדיפוזיה עתיר המשאבים על מרחב הפיקסלים הגדול, הוא מתבצע על ייצוג לטנטי קטן, מה שחוסך זמן וזיכרון."
  },
  {
    "type": "mc",
    "question": "כיצד פועל מנגנון ה-Cross-Attention במודל כמו Stable Diffusion?",
    "options": [
      "הוא משווה בין אזורים שונים בתוך התמונה כדי למצוא דמיון מבני",
      "הוא משלב מידע מהטקסט (prompt) לתוך תהליך יצירת התמונה",
      "הוא מחליף לחלוטין את שכבות הקונבולוציה במודל",
      "הוא אחראי על הוספת הרעש בתהליך ה-Forward"
    ],
    "correctAnswerIndex": 1,
    "explanation": "מנגנון ה-Cross-Attention משמש כגשר בין המידע הטקסטואלי (שמספק את ה-Keys וה-Values) לבין ייצוג התמונה הנוכחי (שמספק את ה-Query). כך המודל 'מבין' אילו חלקים בטקסט רלוונטיים לאילו אזורים בתמונה."
  },
  {
    "type": "mc",
    "question": "מהו ההבדל העיקרי בין תהליך הדגימה (sampling) של DDPM ו-DDIM?",
    "options": [
      "DDIM דורש יותר שלבים ליצירת תמונה באיכות דומה",
      "DDPM הוא תהליך דטרמיניסטי, בעוד DDIM הוא סטוכסטי",
      "DDIM מאפשר דגימה מהירה משמעותית עם פחות שלבים ויכול להיות דטרמיניסטי",
      "DDIM משתמש במודל חיצוני (classifier) כדי להנחות את התהליך, בניגוד ל-DDPM"
    ],
    "correctAnswerIndex": 2,
    "explanation": "DDIM הוא הכללה של DDPM המאפשרת תהליך דגימה לא-מרקובי. זה מאפשר 'לקפוץ' מספר שלבים ולהפיק תמונות באיכות גבוהה בזמן קצר בהרבה. בנוסף, על ידי קביעת השונות לאפס, תהליך הדגימה הופך לדטרמיניסטי."
  },
  {
    "type": "mc",
    "question": "בשיטת Classifier Guidance, איזה רכיב נוסף נדרש בזמן הדגימה (inference)?",
    "options": [
      "רשת Generative Adversarial Network (GAN) נוספת",
      "מודל סיווג (classifier) שאומן על תמונות רועשות",
      "מודל קידוד טקסט כמו CLIP",
      "רשת Decoder נוספת לשחזור התמונה"
    ],
    "correctAnswerIndex": 1,
    "explanation": "בשיטת Classifier Guidance, משתמשים במודל סיווג חיצוני, שאומן מראש על תמונות ברמות רעש שונות. הגרדיאנט של הסיווג משמש כדי 'לדחוף' את תהליך הדגימה לכיוון יצירת תמונה שתתאים לקטגוריה הרצויה."
  },
  {
    "type": "mc",
    "question": "מהו הטרייד-אוף המרכזי בשימוש ב-Classifier-Free Guidance (CFG)?",
    "options": [
      "זמן דגימה מהיר יותר על חשבון צריכת זיכרון גבוהה יותר",
      "יציבות אימון גבוהה יותר על חשבון איכות תמונה נמוכה יותר",
      "התאמה גבוהה יותר להתניה (prompt) על חשבון מגוון נמוך יותר של התוצאות",
      "מורכבות מודל נמוכה יותר על חשבון זמן אימון ארוך יותר"
    ],
    "correctAnswerIndex": 2,
    "explanation": "ככל שמגבירים את עוצמת ההנחיה (guidance scale), התמונות המתקבלות נאמנות יותר לטקסט המנחה, אך על חשבון המגוון. המודל 'מתביית' על ייצוגים מוכרים של המושגים בטקסט ומייצר פחות וריאציות יצירתיות."
  },
  {
    "type": "mc",
    "question": "איזו ארכיטקטורה החליפה את ה-U-Net במודל (DiT (Diffusion Transformer?",
    "options": [
      "רשת קונבולוציה פשוטה (CNN)",
      "רשת נסגת (RNN)",
      "ארכיטקטורת Vision Transformer (ViT)",
      "מודל Autoencoder"
    ],
    "correctAnswerIndex": 2,
    "explanation": "החידוש המרכזי של DiT הוא החלפת רשת ה-U-Net, ששימשה באופן מסורתי לחיזוי הרעש במודלי דיפוזיה, בארכיטקטורת טרנספורמר. זה מאפשר סקיילביליות טובה יותר וניצול יעיל של חומרה מודרנית."
  },
  {
    "type": "mc",
    "question": "בהשוואה למודלי GAN, מה נחשב לרוב כיתרון של מודלי דיפוזיה?",
    "options": [
      "תהליך דגימה (sampling) מהיר יותר באופן משמעותי",
      "תהליך אימון יציב יותר והימנעות מ-mode collapse",
      "דרישות זיכרון נמוכות יותר בזמן האימון",
      "מרחב לטנטי (latent space) מובנה ומאורגן יותר"
    ],
    "correctAnswerIndex": 1,
    "explanation": "מודלי דיפוזיה ידועים בכך שתהליך האימון שלהם, המבוסס על Maximum Likelihood, יציב יותר מהאימון האדברסריאלי של GANs. הם גם פחות נוטים לבעיית 'mode collapse', ולכן מייצרים דגימות מגוונות יותר."
  },
  {
    "type": "mc",
    "question": "מה תפקיד ה-VAE (Variational Autoencoder) במודל Latent Diffusion?",
    "options": [
      "לחזות את הרעש בכל שלב של תהליך הדיפוזיה",
      "לדחוס את התמונה למרחב לטנטי קטן (encoder) ולשחזר אותה ממנו (decoder)",
      "לסווג את התמונה המיוצרת כדי להנחות את התהליך",
      "להמיר את הטקסט לייצוג וקטורי (embedding)"
    ],
    "correctAnswerIndex": 1,
    "explanation": "בארכיטקטורת LDM, ה-VAE משמש לשתי מטרות: ה-Encoder שלו דוחס את תמונת הקלט לייצוג לטנטי קומפקטי, וה-Decoder שלו לוקח את הייצוג הלטנטי 'הנקי' בסוף תהליך הדיפוזיה ומשחזר ממנו את התמונה הסופית ברזולוציה גבוהה."
  },
  {
    "type": "mc",
    "question": "כיצד המידע על שלב הזמן (timestep 't') מוזן לרוב לרשת ה-U-Net במודלי דיפוזיה?",
    "options": [
      "כפיקסל בודד שערכו הוא t",
      "הוא אינו מוזן כלל, הרשת לומדת אותו בעצמה",
      "הוא מומר לוקטור embedding ומוזרק לשכבות הביניים של הרשת",
      "הוא משורשר כערוץ נוסף לתמונת הקלט"
    ],
    "correctAnswerIndex": 2,
    "explanation": "הערך הסקלרי של t מומר לייצוג וקטורי עשיר (embedding), לרוב באמצעות רשת MLP קטנה. וקטור זה מוזרק לשכבות השונות של ה-U-Net כדי לאפשר למודל להתנות את פעולת ניקוי הרעש בהתאם לשלב הנוכחי בתהליך."
  },
  {
    "type": "mc",
    "question": "בתהליך הדגימה של מודל דיפוזיה, ממה מתחילים?",
    "options": [
      "מתמונה אמיתית מה-dataset",
      "מוקטור אקראי מהתפלגות אחידה",
      "מתמונה ריקה (כל הפיקסלים 0)",
      "מרעש גאוסיאני טהור באותם ממדים של התמונה הרצויה"
    ],
    "correctAnswerIndex": 3,
    "explanation": "תהליך יצירת תמונה חדשה (sampling) מתחיל מהנקודה הסופית של תהליך ה-Forward, כלומר מתמונת רעש גאוסיאני טהור. משם, המודל מבצע תהליך הדרגתי של ניקוי רעש עד לקבלת תמונה ברורה."
  },
  {
    "type": "mc",
    "question": "איזו פונקציית הפסד (loss function) היא הנפוצה ביותר לאימון מודל DDPM?",
    "options": [
      "Adversarial Loss",
      "Cross-Entropy Loss",
      "L2 Loss (MSE) בין הרעש האמיתי לרעש שהמודל חזה",
      "Perceptual Loss"
    ],
    "correctAnswerIndex": 2,
    "explanation": "מטרת האימון היא שהמודל ילמד לחזות את הרעש שהוסף. הדרך הפשוטה והיעילה למדוד את ההצלחה בכך היא לחשב את המרחק הריבועי הממוצע (MSE או L2 Loss) בין וקטור הרעש האמיתי לוקטור הרעש שהמודל ניבא."
  },
  {
    "type": "mc",
    "question": "מה מאפיין את השלבים המוקדמים של תהליך ה-Reverse Denoising (ערך t גבוה)?",
    "options": [
      "המודל מתמקד בשיפור פרטים עדינים וטקסטורות",
      "המודל קובע את המבנה הכללי, הקומפוזיציה והצבעים הראשיים של התמונה",
      "המודל מוסיף חזרה כמות קטנה של רעש כדי לשפר גיוון",
      "המודל כמעט ולא משנה את התמונה"
    ],
    "correctAnswerIndex": 1,
    "explanation": "בשלבים המוקדמים של הדגימה (כש-t קרוב ל-T), התמונה היא בעיקר רעש. בשלבים אלו המודל לומד וקובע את התכונות הגלובליות והתדרים הנמוכים של התמונה, כמו צורות כלליות וצבעוניות בסיסית."
  },
  {
    "type": "mc",
    "question": "במודל Stable Diffusion, איזה רכיב משמש לרוב כמקודד הטקסט (Text Encoder)?",
    "options": ["BERT", "GPT-3", "Word2Vec", "CLIP"],
    "correctAnswerIndex": 3,
    "explanation": "מודל Stable Diffusion משתמש במקודד הטקסט של מודל CLIP כדי להמיר את ה-prompt לייצוג וקטורי עשיר סמנטית. ייצוג זה משמש לאחר מכן להנחיית תהליך יצירת התמונה באמצעות מנגנון ה-Cross-Attention."
  },
  {
    "type": "mc",
    "question": "מה המשמעות של תהליך דגימה דטרמיניסטי במודל DDIM?",
    "options": [
      "התהליך תמיד יתכנס לתמונה המקורית ששימשה לאימון",
      "עבור אותו רעש התחלתי (x_T), התוצאה הסופית (x_0) תהיה תמיד זהה",
      "המודל לא משתמש ברעש כלל במהלך הדגימה",
      "איכות התמונה הסופית תמיד תהיה גבוהה יותר"
    ],
    "correctAnswerIndex": 1,
    "explanation": "כאשר קובעים את פרמטר השונות בתהליך הדגימה של DDIM לאפס, התהליך הופך לדטרמיניסטי. זה אומר שהאקראיות היחידה מגיעה מבחירת הרעש ההתחלתי. כתוצאה מכך, אותו רעש התחלתי תמיד יוביל לאותה תמונה סופית."
  },
  {
    "type": "mc",
    "question": "מלבד טקסט, איזה סוג של התניה (conditioning) ניתן לשלב במודלי דיפוזיה?",
    "options": [
      "אף סוג אחר, הם מוגבלים לטקסט בלבד",
      "רק וקטור סגנון בודד",
      "ניתן להשתמש בתמונות, מפות סגמנטציה, או תוויות קטגוריות",
      "רק מידע על רמת הרעש"
    ],
    "correctAnswerIndex": 2,
    "explanation": "מודלי דיפוזיה גמישים מאוד וניתן להתנות אותם על מגוון רחב של קלטים, כולל תיאורים טקסטואליים, תמונות אחרות (למשימות image-to-image), מפות סגמנטציה סמנטיות, ואף תוויות קטגוריה פשוטות."
  },
  {
    "type": "mc",
    "question": "מה הרעיון מאחורי שיטת 'שרשור' הטוקנים ב-DiT כחלופה ל-Cross Attention?",
    "options": [
      "זה מפחית את מספר הפרמטרים במודל",
      "זה מאפשר למודל לטפל בטוקנים של התמונה והטקסט יחד כרצף אחד באמצעות Self-Attention",
      "זה דורש אימון של שני מודלים נפרדים",
      "זה מיועד רק למשימות שאינן מותנות בטקסט"
    ],
    "correctAnswerIndex": 1,
    "explanation": "במקום להשתמש במנגנון Cross-Attention ייעודי להזרקת מידע מהטקסט לתמונה, ניתן פשוט לשרשר את טוקני הטקסט וטוקני התמונה לרצף אחד ולהפעיל עליו Self-Attention. גישה זו מפשטת את הארכיטקטורה ומאפשרת אינטראקציה דו-כיוונית בין הטקסט לתמונה."
  },
  {
    "type": "mc",
    "question": "באיזה שלב בתהליך של LDM מופעל ה-Decoder של ה-VAE?",
    "options": [
      "בכל שלב ושלב של תהליך ה-denoising",
      "רק בהתחלה, כדי ליצור את הייצוג הלטנטי",
      "רק בסוף, לאחר שתהליך ה-denoising במרחב הלטנטי הסתיים",
      "הוא אינו מופעל כלל בזמן יצירת תמונה חדשה"
    ],
    "correctAnswerIndex": 2,
    "explanation": "כל תהליך ניקוי הרעש האיטרטיבי מתבצע במרחב הלטנטי. רק לאחר שהתהליך מסתיים ומתקבל ייצוג לטנטי 'נקי', מפעילים את ה-Decoder פעם אחת כדי להמיר את הייצוג הלטנטי לתמונה הסופית במרחב הפיקסלים."
  },
  {
    "type": "mc",
    "question": "מדוע חשוב שמודל סיווג המשמש ל-Classifier Guidance יאומן על תמונות רועשות?",
    "options": [
      "זה לא חשוב, ניתן להשתמש בכל מודל סיווג",
      "כי אחרת המודל יתקשה מאוד בזמן האימון",
      "כי בזמן הדגימה, המודל צריך להנחות תמונות שנמצאות בשלבי רעש שונים (x_t)",
      "כדי להפוך את תהליך הדגימה למהיר יותר"
    ],
    "correctAnswerIndex": 2,
    "explanation": "ההנחיה מתבצעת לאורך כל תהליך ה-denoising, שבו התמונות הן רועשות. אם מודל הסיווג אומן רק על תמונות נקיות, הוא לא ידע לתת הנחיה משמעותית כשיקבל כקלט תמונה רועשת, ולכן ההנחיה לא תהיה יעילה."
  },
  {
    "type": "open",
    "question": "הסבר במילים שלך מדוע מודלי דיפוזיה נוטים פחות לבעיית 'mode collapse' בהשוואה למודלי GAN.",
    "correctAnswerText": "ב-GANs, ה-Generator יכול למצוא מספר קטן של דוגמאות ש'מרמות' את ה-Discriminator ולהתמקד רק בייצור שלהן, תוך התעלמות משאר התפלגות הדאטה (mode collapse). במודלי דיפוזיה, תהליך האימון מבוסס על מזעור שגיאה (L2 loss) בחיזוי הרעש על כל דוגמה מה-dataset. מטרה זו 'מכריחה' את המודל ללמוד את כל התפלגות הנתונים בצורה טובה, ולא רק תת-קבוצה קטנה שלה, מה שמוביל למגוון רחב יותר של תוצאות.",
    "explanation": "ההבדל נובע מפונקציית המטרה של האימון. אימון אדברסריאלי ב-GAN יכול להגיע לשיווי משקל נאש לא יציב, בעוד שמטרת ה-likelihood במודלי דיפוזיה מעודדת כיסוי מלא של התפלגות הנתונים."
  },
  {
    "type": "open",
    "question": "תאר את שני השלבים העיקריים בתהליך יצירת תמונה באמצעות Latent Diffusion Model (LDM).",
    "correctAnswerText": "השלב הראשון הוא תהליך הדיפוזיה ההפוך (reverse diffusion) במרחב הלטנטי: מתחילים מרעש אקראי בממדים נמוכים, ורשת U-Net מנקה אותו באופן איטרטיבי עד לקבלת ייצוג לטנטי נקי. השלב השני הוא פענוח: הייצוג הלטנטי הנקי מוזן ל-Decoder של VAE, אשר ממפה אותו חזרה למרחב הפיקסלים ויוצר את התמונה הסופית ברזולוציה גבוהה.",
    "explanation": "התהליך מורכב משני חלקים: (1) יצירת התוכן הסמנטי במרחב לטנטי יעיל, ו-(2) המרה של התוכן הזה לתמונה ויזואלית מפורטת. ההפרדה הזו היא המפתח ליעילות של LDM."
  },
  {
    "type": "open",
    "question": "כיצד עובדת שיטת Classifier-Free Guidance (CFG) מבלי להשתמש במודל סיווג חיצוני?",
    "correctAnswerText": "במהלך האימון, מודל הדיפוזיה לומד לחזות את הרעש בשני מצבים: פעם אחת עם התניה (למשל, טקסט) ופעם אחת בלי (התניה ריקה). בזמן הדגימה, המודל מבצע שתי תחזיות בכל שלב: תחזית מותנית ותחזית לא מותנית. התחזית הסופית היא שילוב של השתיים, כאשר 'דוחפים' את התחזית המותנית בכיוון ההפוך מהתחזית הלא מותנית, בעוצמה הנקבעת על ידי פרמטר (guidance scale).",
    "explanation": "הרעיון הוא להשתמש במודל עצמו כדי לייצר את כיוון ההנחיה. ההפרש בין החיזוי המותנה ללא-מותנה משמש כקירוב לגרדיאנט שהיה מתקבל ממודל סיווג חיצוני, ובכך נחסך הצורך ברכיב נוסף."
  },
  {
    "type": "open",
    "question": "מה ההבדל המהותי בין Self-Attention ל-Cross-Attention בהקשר של מודלים גנרטיביים?",
    "correctAnswerText": "ב-Self-Attention, הרשת בוחנת את הקשרים בין אלמנטים שונים בתוך אותו המקור. לדוגמה, היא לומדת את הקשר בין פיקסלים שונים באותה תמונה. ב-Cross-Attention, הרשת בוחנת את הקשרים בין אלמנטים משני מקורות מידע שונים. לדוגמה, היא לומדת את הקשר בין מילים בתיאור טקסטואלי לבין אזורים ספציפיים בתמונה.",
    "explanation": "Self-Attention הוא 'מבט פנימה' לתוך ייצוג בודד, בעוד ש-Cross-Attention הוא 'גשר' המקשר בין שני ייצוגים שונים, כמו טקסט ותמונה."
  },
  {
    "type": "open",
    "question": "מדוע תהליך הדגימה (sampling) במודלי דיפוזיה מוקדמים (כמו DDPM) הוא איטי?",
    "correctAnswerText": "התהליך איטי מכיוון שהוא איטרטיבי ודורש צעדים קטנים רבים. בכל שלב, המודל צריך לבצע 'forward pass' מלא של רשת נוירונים גדולה כדי לחזות את הרעש ולהתקדם רק צעד אחד קטן בתהליך הניקוי. כדי לעבור מרעש טהור לתמונה נקייה נדרשים מאות או אלפי צעדים כאלה, מה שהופך את התהליך למצטבר ואיטי.",
    "explanation": "בניגוד למודלי GAN שיכולים לייצר תמונה במעבר אחד, מודלי דיפוזיה בונים את התמונה בהדרגה. כל שלב תלוי בקודמו, והצורך במספר רב של שלבים כאלה הוא הגורם המרכזי לאיטיות."
  },
  {
    "type": "open",
    "question": "הסבר מהי הנוסחה הסגורה בתהליך ה-Forward Diffusion, ומדוע היא שימושית לאימון.",
    "correctAnswerText": "הנוסחה הסגורה מאפשרת לחשב ישירות את התמונה הרועשת בכל שלב זמן t (כלומר, x_t) ישירות מהתמונה המקורית (x_0) ורעש גאוסיאני, מבלי צורך לבצע את כל T הצעדים הרקורסיביים. היא שימושית מאוד לאימון כי היא מאפשרת לדגום זוגות של (x_t, t) באופן יעיל ואקראי בכל איטרציה, במקום לדמות את כל התהליך מחדש בכל פעם. זה מזרז משמעותית את יצירת דאטה לאימון.",
    "explanation": "במקום ריצה רקורסיבית יקרה, הנוסחה הסגורה מספקת קיצור דרך חישובי המאפשר גישה ישירה לכל שלב בתהליך ההרעשה, מה שהופך את האימון למקבילי ויעיל."
  },
  {
    "type": "open",
    "question": "כיצד מודל Stable Diffusion משלב התניה של טקסט בתהליך יצירת התמונה?",
    "correctAnswerText": "ראשית, הטקסט (prompt) מקודד לייצוג וקטורי באמצעות מקודד טקסט של CLIP. לאחר מכן, בתוך רשת ה-U-Net שפועלת במרחב הלטנטי, ייצוג הטקסט מוזרק לשכבות באמצעות מנגנון Cross-Attention. בכל שלב, ייצוג התמונה הנוכחי יוצר את ה-Query, בעוד שייצוג הטקסט מספק את ה-Key וה-Value. זה מאפשר למודל ליישר (align) את תוכן התמונה עם המשמעות של הטקסט.",
    "explanation": "השילוב מתבצע על ידי הזרקת מידע סמנטי מהטקסט ישירות לתהליך ה-denoising הויזואלי, מה שמאפשר שליטה מדויקת על התוכן המיוצר."
  },
  {
    "type": "open",
    "question": "מהו הרעיון מאחורי ראיית מודלי דיפוזיה כ-Score Functions?",
    "correctAnswerText": "ניתן לראות את המשימה של המודל לא כחיזוי רעש, אלא כלימוד של ה-Score Function של התפלגות הנתונים. ה-Score Function היא הגרדיאנט של לוג-ההסתברות של הדאטה. כלומר, עבור כל נקודה (תמונה רועשת), המודל לומד את הכיוון שבו צריך לנוע כדי להגדיל את סבירות התמונה. תהליך הדגימה הוא למעשה 'טיפוס' לאורך שדה הגרדיאנטים הזה, מרעש אקראי לכיוון אזורים של סבירות גבוהה (תמונות ריאליסטיות).",
    "explanation": "זוהי פרשנות מתמטית אלטרנטיבית ועמוקה יותר לתהליך הדיפוזיה, המקשרת אותו לתחום של Score-Based Generative Modeling. במקום לחשוב על 'ניקוי רעש', חושבים על 'זרימה' לכיוון אזורים סבירים יותר בהתפלגות."
  },
  {
    "type": "open",
    "question": "מה המוטיבציה להחלפת ארכיטקטורת U-Net בטרנספורמר (כמו במודל DiT)?",
    "correctAnswerText": "המוטיבציה העיקרית היא סקיילביליות (scalability). ארכיטקטורות טרנספורמר הראו הצלחה גדולה ביכולת שלהן להשתפר ככל שמגדילים את גודל המודל וכמות הנתונים, הן בתחום השפה והן בראייה ממוחשבת. המעבר לטרנספורמר מאפשר למודלי הדיפוזיה לנצל טוב יותר חומרה מודרנית ולהגיע לאיכות גבוהה יותר במודלים גדולים מאוד.",
    "explanation": "בעוד ש-U-Net יעילה, טרנספורמרים הוכיחו את עצמם כארכיטקטורה בעלת יכולת גדילה טובה יותר, מה שהופך אותם למתאימים יותר עבור הדור הבא של מודלים גנרטיביים גדולים."
  },
  {
    "type": "open",
    "question": "הסבר בקצרה את תהליך האימון של מודל דיפוזיה.",
    "correctAnswerText": "בכל איטרציית אימון, חוזרים על השלבים הבאים: 1. דוגמים תמונה אמיתית מה-dataset. 2. דוגמים שלב זמן אקראי 't' בין 1 ל-T. 3. דוגמים רעש גאוסיאני סטנדרטי. 4. משתמשים בנוסחה הסגורה כדי ליצור את התמונה הרועשת x_t מהתמונה המקורית והרעש. 5. מזינים את התמונה הרועשת x_t ואת שלב הזמן t למודל. 6. מחשבים את ההפסד (loss) על ידי השוואת הרעש שהמודל חזה לרעש האמיתי שדגמנו. 7. מבצעים צעד של Gradient Descent כדי לעדכן את משקולות המודל.",
    "explanation": "התהליך הוא למידה מונחית (supervised) שבה הקלט הוא תמונה רועשת וה'תשובה הנכונה' (label) היא הרעש שהוסף. המטרה היא ללמד את המודל למפות כל תמונה רועשת לרעש שיצר אותה."
  }
]
